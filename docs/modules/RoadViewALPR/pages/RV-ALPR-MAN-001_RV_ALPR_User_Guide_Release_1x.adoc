:docproductname: RoadView ALPR
:shortprodname: RoadView
= {docproductname}
//enable the TOC to be placed in a specific position
:toc: macro
//!sectnum momentarily stops section numbering
:!sectnums:

// This "invisible" text helps lunr search put this page
// at the top of the results list when searching
// for a specific product name
[.white]#{shortprodname}#

// discrete removes these headers from the TOC
[discrete]
=== User Guide
[discrete]
=== Release 1.x

Doc. No. RV-ALPR-MAN-001
//blank line helps to separate doc no. from TOC
{empty} +
{empty} +

// restore section numbering from here on
:sectnums: all

// place the TOC in this specific position (capability enabled by :toc: macro at start
// of file
toc::[]
== About This Document

=== Who Should Read this Document

This document is for:

[square]
* *Technical personnel* who want to install, configure, maintain and use {docproductname} in their ALPR systems
* *Project managers* who want to understand {docproductname}'s capabilities

[#s_Related-Documents]
=== Recommended Reading/Related Documents

.Related Documents

[width="100%",cols="53%,47%",options="header",]
|===
|Doc. No. |Title
|xref:RoadViewALPR:DocList.adoc[RV-ALPRrrr-MAN-001] |{docproductname} Release Notes (for Release rrr)
|xref:RoadViewALPR:DocList.adoc[RV-VDANLYTCS-TDSHEET] |{shortprodname} Video Analytics Technical Data Sheet
|xref:IZIO:DocList.adoc[IZIO-6060-MAN-001] |IZIO Digital IO Controller Installation and User Guide
|xref:IZIO:DocList.adoc[IZIO-6060-TECH-002] |ADAM (IZIO) P2P Configuration
a|
xref:IZREMRELAY:DocList.adoc[IZREMRELAY-REV-A-TDSHEET]

xref:IZREMRELAY:DocList.adoc[Supporting Documentation]

|IZ-REM-RELAY Remote (Web) Relays Series: Data Sheet and supporting documentation
|xref:IZDiscovery:DocList.adoc[IZ Discovery Utility] |IZ Discovery Utility software components
|xref:ZAP-4-5:DocList.adoc[ZAP-450-SDK-002] |ZAP: INEX Technologies Application Protocol, Version 4.5
|xref:ZAP-4-5:DocList.adoc[API-HTTPM-ICD-00n_INEX_HTTP_API_Rx_y_v_W] |INEX HTTP API for Major Version "M", Release "x.y"; document version W
|xref:IZMONSERVER:DocList.adoc[IZMSAPI-HTTP-ICD-041] |IZMonitoring Server: Camera Monitoring API
|xref:IZMONSERVER:DocList.adoc[IZMSAPI-HTTP-ICD-042] |IZMonitoring Server API
|xref:IZCentral:DocList.adoc[IZCENTRAL-CORE-MAN-001] |IZCentral User Guide
|xref:EULA:DocList.adoc[EULA-400-DOC-001] |Software End User License Agreement (includes list of open source software)
|xref:SLN-AmanoONE:DocList.adoc[RV-AMANO-MAN-001] |INEX ALPR Installation for AMANO
|xref:SLN-IZCloudIntegration:DocList.adoc[RV-IZCLOUD-MAN-001] |INEX IZCloud Integration
|xref:SLN-TIBA:DocList.adoc[RV-TIBA-MAN-001] |INEX TIBA Integration
|===

=== Applicability

This document is applicable to {docproductname} software, release 1.15.64 and above.

=== Support

Contact our support team via our website: http://www.inextechnologies.com

== Glossary of Terms

.Glossary

[width="100%",cols="25%,75%",options="header",]
|===
|Term |Explanation
|ALPR |Automatic License Plate Recognition
|DHCP |Dynamic Host Configuration Protocol. A DHCP server assigns a unique Internet Protocol (IP) address to each device connected to a network.
|DPU |DPU is a generic term for INEX/TECH Data Processing Units. {shortprodname} software can run on INEX/TECH DPUs with graphic processors, or on ALPR All-in-one Camera Systems with built-in processors.
|IZ |INEX/ZAMIR (former company name; now called INEX Technologies, also called INEX/TECH)
|IZ ALPR system |An Automatic License Plate Recognition system utilizing cameras and {shortprodname} software. The IZ ALPR system can capture LPR Events, and transmit them to other systems such as IZCentral.
|IZCentral |Server software that communicates with one or more IZ ALPR systems. IZCentral provides a central repository for all LPR Events generated by the {shortprodname}(s). IZCentral can also interface with many 3rd party systems via their proprietary protocols.
|LPR Event |The identified occurrence of a passing vehicle by the IZ ALPR System. An LPR Event includes metadata (location, lane identifiers, timestamp, the identified license plate number, recognition confidence, and more), plus a set of related images; typically, an Overview image, an LPR camera image and an image of the license plate. Also called a Vehicle Event or Event. An Event may include images from more than one camera in the same Lane.
|{shortprodname} |The software responsible for capturing LPR Events, and transmitting them to other systems.
|.NET |Software framework that runs primarily on Microsoft Windows. See also WCF.
|NIC |Network Interface Card
|RTSP |Real Time Streaming Protocol. A network protocol designed to control streaming media servers.
|Trigger |A command sent to an IZ ALPR system to create an LPR Event. Trigger sources can be from hardware signals, generated by software, or sent by a 3^rd^ party system via various protocols.
|WCF |Windows Communication Foundation. A Microsoft class library that is included with the .NET Framework. See also .NET.
|ZAP |Zamir Application Protocol - Proprietary INEX Technologies protocol for interfacing with an IZ ALPR system and IZCentral.
|===

[#s_System-Requirements]

== System Requirements

You will need to provide a laptop computer to use for configuration. +++<u>+++If you will be using the laptop outdoors, the screen must be able to be seen in strong sunlight+++</u>+++.
{empty} +
Required software:
[square]
* Windows 10 or above - with .NET 4.5 enabled in "Windows Features"
* Internet Explorer browser version 11 or higher, or the latest version of Chrome

[NOTE]

========================================

You can add an IE Tab extension to Chrome at this link (to enable access to the Flexwatch camera configuration application): +
https://chrome.google.com/webstore/detail/ie-tab/hehijbfgiekmjfkfjpbkbammjbdenadd

========================================

[#s_Quick-Overview-of-Steps]

== Quick Overview of Steps

[square]
* Reserve IP addresses for the components in your ALPR system - {shortprodname} computer(s) and camera(s) - see <<s_Reserving-IP-Addresses-in-your-Network>> .
* Use IZ Discovery to find the initial IP Addresses of the cameras connected to your network - see <<s_Determining-the-IP-Addresses-of-the-Connected-Cameras>> .
* Log into each camera, and change its IP address according to the requirements of your network. +++<u>+++Use fixed addresses+++</u>+++. Record these new addresses for use in {shortprodname} configuration. See <<s_Changing-the-IP-Addresses-of-the-Cameras>> .
* Use IZ Discovery to find he IP address of the {shortprodname} computer. Change the computer's IP address according to the requirements of your network. See <<s_Determining-the-IP-Address-of-the-RoadView-Computer-with-IZ-Discovery>> and <<s_Changing-the-RoadView-Computers-IP-Address-and-Network-Settings>> .
* Review the different trigger sources and sequences, and triggering operational modes (see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>)
* Log in to {shortprodname}, and configure {shortprodname} using the Settings tab, including adding the connected Lanes and cameras - see <<s_Settings-Tab>> .
* On the Calibration tab, adjust the zoom and focus to get a clear, sharp picture. Set the expected plate minimum and maximum width, capture zone and other parameters. See <<s_Search-Tab>> .
* On the Live tab, verify that Events are being generated for each vehicle passing each camera, and that the recognition has sufficient accuracy and confidence. See <<s_Live-Journal-Tab>> .
* Use the Search tab to find records stored in the {shortprodname} database. See <<s_Search-Tab>> .

[#s_System-Overview]

== System Overview

{shortprodname} is advanced ALPR software that reads license plates using sophisticated image recognition algorithms, and creates LPR Events. {shortprodname} sends LPR Event data via HTTP, the proprietary INEX ZAP protocol or other protocols to other systems, typically IZCentral (see the IZCentral User Guide - see <<s_Related-Documents>>). {shortprodname} can be configured and monitored using a web-based GUI.

[NOTE]

========================================

{shortprodname} can send Events to IZCentral or 3rd party systems using various different protocols. See <<s_Trigger-Sources-and-Trigger-Modes-Overview>> .

========================================

[#s_Preparation-for-Configuration]

== Preparation for Configuration

[#s_Connecting-a-Computer-Laptop-to-the-Network]

=== Connecting a Computer/Laptop to the Network

.Connecting a Laptop

image::image1.png[image,width=312,height=195]

Connect your laptop to the same network switch the computer running {shortprodname} is connected to.

[#s_Reserving-IP-Addresses-in-your-Network]

=== Reserving IP Addresses in your Network

The INEX cameras have been pre-configured with default IP addresses. You will probably need to change these addresses to conform to the requirements of your network. Be sure that you have IP addresses reserved for all components of your ALPR system ({shortprodname} computer and cameras).

[#s_Determining-the-IP-Addresses-of-the-Connected-Cameras]

=== Determining the IP Addresses of the Connected Cameras

See your camera's Installation Guide for an explanation of how to determine the initial IP addresses of cameras on your network (using IZ Discovery). You will need this information to log into the cameras, and to change the cameras' IP addresses.

[#s_Changing-the-IP-Addresses-of-the-Cameras]

=== Changing the IP Addresses of the Cameras

See your camera's Installation Guide for an explanation of how to log in to a camera, and how to edit its IP address (fixed addresses are highly recommended). Record the new addresses; you will need them to configure the {shortprodname} software.

[#s_Determining-the-IP-Address-of-the-RoadView-Computer-with-IZ-Discovery]

=== Determining the IP Address of the {shortprodname} Computer with IZ Discovery

The IZ Discovery utility discovers all active devices connected to the network, and displays a list of their network parameters. These devices can include cameras and computers.

[IMPORTANT]

========================================

If any device on your network is connected via wireless, IZ Discovery will not recognize the device. In addition, if the computer running IZ Discovery is connected via wireless, you will not see any devices displayed.

========================================

. Download the IZ Discovery software (see <<s_Related-Documents>>)

. Run IZ Discovery

. When IZ Discovery first runs, you may see a Windows security warning. If so, click Run.

. If you see a message related to the Windows firewall, click Allow.

. IZ Discovery will start and display a list of devices on the network, according to their serial numbers (see <<f_IZ-Discovery-Utility>>).

.. Scroll down to find the device you are interested in. You can double-click to view/edit a specific device's IP address parameters (see <<s_Changing-the-RoadView-Computers-IP-Address-and-Network-Settings>>).

.. Click Clear List to refresh the discovery process.

+

[#f_IZ-Discovery-Utility]

.IZ Discovery Utility

+
image::image2.PNG[image,width=723,height=485]

+

. If IZ Discovery does not recognize a device:
[disc]
** Press the device's reset button (if available)
** Reset the device by shutting off power/removing the LAN cable, waiting 5 seconds, and reapplying power
** Check the LAN cable connected between your laptop and the network, and the LAN cable connected between the device and the LAN switch. Replace the cable(s) and try to run IZ Discovery again.

[#s_Changing-the-RoadView-Computers-IP-Address-and-Network-Settings]

=== Changing the {shortprodname} Computer's IP Address and Network Settings


.Changing the Computer's Network Settings

image::image3.png[image,width=272,height=276]


[NOTE]

========================================

The device's IP Address +++<u>+++cannot+++</u>+++ be set to 10.10.2.xx or 10.10.3.xx

*+++<u>+++It is highly recommended to use a fixed IP address (not DHCP)+++</u>+++*. A fixed IP address enables you to access the computer using the same URL every time, even after unexpected power outages (see <<s_Logging-In-and-Logging-Out>>).

A dynamic IP address may change upon device reboot. Before opening the web interface, you will have to find the current IP address of the device using IZ Discovery.

If you want to copy the IP address (for login to the device) you will need to uncheck the DHCP checkbox momentarily to make the address field accessible.

You can also change the IP address using the {shortprodname} Settings tab (see <<s_Network-Settings>>).

========================================

To change the device's mode (fixed or dynamic [DHCP]), or IP address:

. Select the relevant line in the list of devices and double-click on it.

. The Network Settings window appears

. To change the mode:

.. Check or uncheck the DHCP box

.. Click Save

. To change the IP address:

.. *Verify that the address is not used by any other device on the network*

.. Be sure to uncheck the DHCP box

.. Enter the network address parameters

.. Write down the new IP Address and click Save

. The change should be reflected in the main dialog. This can take about a minute until the IP is obtained. If you do not see the change after this time, close IZ Discovery, and then reopen it.

. Verify that the IP address parameters have been changed to the ones you wanted. If not, you will have to log into the device (see <<s_Logging-In-and-Logging-Out>>) and change the IP address (see <<s_Network-Settings>>).

[#s_Logging-In-and-Logging-Out]

== Logging In and Logging Out

[#s_Logging-In]

=== Logging In

. Open a browser (latest version of Chrome or IE 11 or higher). Type in the IP address of the {shortprodname} computer. For example: +
http://192.115.120.76/
+
[IMPORTANT]

========================================

The {shortprodname} GUI can now be accessed using https at the start of the URL. This enables secure communications with the {shortprodname} GUI. However, due to the type of certification being used, you will see a security error message. Use the options on this warning screen to manually proceed to the {shortprodname} GUI.

========================================

. In the login screen, enter the default username and password: (root, root):

+
.Logging In to the Computer
image::image4.png[image,width=209,height=143]
+
. You should see the {shortprodname} Live (Journal) tab (see <<s_Live-Journal-Tab>>). To configure {shortprodname}, switch to the Settings tab (see <<s_Settings-Tab>>).

[#s_Logging-Out-Multi-line-Menu-Icon]

=== Logging Out (Multi-line Menu Icon)

[square]
* Click on the multi-line menu icon at the upper right of the {shortprodname} screen
* Select "Logout"

.Logout (Multi-line Menu)
image::image5.png[image,width=136,height=113]

[#s_Trigger-Sources-and-Trigger-Modes-Overview]

== Trigger Sources and Trigger Modes Overview

A trigger is a command sent to an IZ ALPR system to create an Event. Triggers can originate from hardware signals, from video analytics or from software/3^rd^ party system protocols.

[#f_Trigger-Sources-and-Sequence]
.Trigger Sources and Sequence
image::image6.png[image,width=624,height=307]

The system constantly captures video frames and stores them in a buffer. However, the Triggering Mode determines if all, or only some of, these frames will be used for license plate recognition and Event building. Other parameters affect how many frames before (pre) and after (post) the trigger will be used:

[square]
* Protocol sections on the Settings tab (see <<s_Settings-Tab>>)
* Direct Trigger (see <<s_Direct-Trigger>>)
* INEX I/O Controller (see <<s_INEX-IO-Controller>>)
* Trigger Offset (see <<s_Trigger-Offset>>)
* The number of Trigger Pre and Trigger Post frames (defined when a camera is configured - see <<s_Cameras>>)

[NOTE]

========================================

DOT cameras take images of USDOT numbers, but do not perform LPR recognition. However, {shortprodname} will generate Events even without LPR recognition.

========================================

The Trigger Operational Modes (set in the Detector Configuration section of the Settings tab - see <<s_Detector-Configuration>>) affect how Events are created (see <<f_Trigger-Operational-Modes>>):

[#f_Trigger-Operational-Modes]

.Trigger Operational Modes
image::image7.png[image,width=632,height=431]

[square]
* +++<u>+++NonTriggered+++</u>+++ - Events are created and reported using LPR video analytics
* +++<u>+++Triggered+++</u>+++ - Events are created and reported when a trigger is received
+
[NOTE]

========================================

Triggered mode must be used for DOT (USDOT number image capture) cameras.

========================================
[square]
* +++<u>+++Hybrid+++</u>+++ - Events are continually created internally by LPR video analytics, but are only reported when a trigger is received. The Event closest in time to the trigger will be reported (sent to storage). See <<s_Detector-Configuration>> where the Hybrid Pre/Post Time parameters are described.
+
[NOTE]

========================================

In Hybrid mode, if no recognition was possible (no vehicle, no plate, unrecognizable plate, etc.), an Event will be created as it would be in Triggered mode. The Event will be created using frames captured at the time the Trigger was received, along with the Trigger Pre and Post frames, instead of using the frames from the NonTriggered video analytics. +
See <<s_Trigger-Sources-and-Trigger-Modes-Overview>> and <<s_Cameras>> .

========================================
[square]
* +++<u>+++NonTriggered With Trigger+++</u>+++ - NonTriggered Events are continually created and reported by LPR video analytics. In addition, Triggered Events are created and reported when a trigger is received.

Each type of Trigger Operational Mode has its own advantages:

[square]
* *Triggered types* require external triggering hardware or software, and are more accurate. All vehicle images are recorded, even if the plate was not recognized. In addition, LPR Events can be generated on demand by third-party systems.
* *NonTriggered types* do not require any external triggering hardware (such as inductive loops). However, they are less accurate.

[#s_Settings-Tab]

== Settings Tab

Use the Settings tab after the first installation or reinstallation of the IZ ALPR system, or when some fundamental parameters need updating. For example, if the Camera System or DPU was moved to a different location (time zone).

.Settings Tab
image::image8.png[image,width=265,height=504]

[NOTE]

========================================

After clicking the Save button at the end of the Detector Configuration section, it will take several seconds before the Live tab can start displaying Events. Also, some defaults and/or available parameters may change, depending on the Detector Configuration "Mode" selected.

========================================

[#s_Software-Version-and-Camera-Information]

=== Software Version and Camera Information

The box at the upper right of the Settings screen shows:

[square]
* The {shortprodname} software version
* The model, part number and serial number of the camera(s) {shortprodname} is communicating with:

.Software Version and Camera Information Section
image::image9.png[image,width=356,height=130]

[#s_Network-Settings]

=== Network Settings

.Network Settings Section
image::image10.png[image,width=416,height=180]
[square]
* If needed, set the {shortprodname} computer's IP address parameters.
* *Remember to click the Save button in this section; the change will be applied immediately.*

[IMPORTANT]

========================================

The Network Settings refer to the +++<u>+++{shortprodname} computer+++</u>+++ (+++<u>+++Camera System or DPU)+++</u>+++ - NOT the computer on which the browser displaying the GUI is running.

* *+++<u>+++It is highly recommended to use a fixed IP address (not DHCP)+++</u>+++*. A fixed IP address enables you to access the computer using the same URL every time, even after unexpected power outages.

========================================

[#s_FTP-SFTP-Settings]

=== FTP/SFTP Settings
.FTP/SFTP Section
image::image11.png[image,width=468,height=204]

[square]
* Select the desired communication protocol - FTP, SFTP, or both {empty}+
*Be sure to click the Save button at the end of this section if you change these protocol selections, or if you enable or disable FTP or SFTP (check boxes).*
* Separate sections will appear for FTP and SFTP, enabling you to click a button to add user(s) who can connect to a {shortprodname} computer via FTP/SFTP
[disc]
** FTP users are automatically added as SFTP users
** Deleting an SFTP user will automatically delete the user from FTP
** The Port is fixed; this is the port that the users' system will use to communicate with the {shortprodname} computer
+
.Adding an SFTP User
image::image12.png[image,width=176,height=129]
[square]
* Each user that appears in the table can be edited or deleted; however, only the password can be edited. In order to rename a user, you will need to delete the existing user and re-enter it.
* Remember to click Save after changing the password.
* If a user is added, deleted or changed (except for a password change), the changes are saved automatically

[#s_Date-and-Time-Settings]

=== Date and Time Settings

[IMPORTANT]

========================================

The Date and Time Settings refer to the location of the +++<u>+++{shortprodname} computer (Camera System or DPU)+++</u>+++ - NOT the computer on which the browser displaying the GUI is running.

The Time Zone selections are organized by continent. For example, the "America/" prefix covers various cities and countries in North America (U.S. and Canada) and South America.

========================================

.Date and Time Settings Section
image::image13.png[image,width=490,height=180]

[square]
* Set Time (Automatically/Manually)
[disc]
** If *Automatic*, the date and time will be updated from a central Network Time server. Select the appropriate server, and the interval at which you want {shortprodname} to poll for the date and time (selected from the Polling Interval dropdown).
[circle]
*** Click the "Update Now" button to update the date and time immediately.
*** The icon (green check mark or red "x") indicates if the URL of the NTP server is correct, and the connection to it was successful.
[disc]
** If *Manual*, click in the *Date and Time* box to display a calendar/time popup. You should also select a *Time Zone*; set it to the local time at the location in which the Camera System/DPU is installed (+++<u>+++not+++</u>+++ the UTC default).
[square]
* *Remember to click the Save button at the end of this section after making changes.*

[#s_HTTP-Integration]

=== HTTP Integration
.HTTP Integration Section
image::image14.png[image,width=698,height=49]

[NOTE]

========================================

{shortprodname} can send Events to IZCentral or 3rd party systems using the INEX HTTP Protocol, INEX ZAP Protocol or other protocols. For details about the INEX HTTP protocol, see the appropriate INEX HTTP API Protocol document - see <<s_Related-Documents>> .

{shortprodname} can send Events via HTTP, and act as both a ZAP Server and ZAP Client - all simultaneously.

If you are using an IZMobileLPI system, contact INEX for details on how to set the HTTP URL parameter.

========================================

[square]
* Click Add HTTP Integration. Note that this feature enables you to use multiple HTTP channels (see <<f_Adding-an-HTTP-Integration>>).
+
[#f_Adding-an-HTTP-Integration]
.Adding an HTTP Integration
image::image15.png[image,width=264,height=384]
+
[square]
* *HTTP URL* - URL for an external system to listen on, in order to receive Events from {shortprodname} via the INEX HTTP protocol (see the appropriate INEX HTTP API Protocol document - see <<s_Related-Documents>>).
+
[NOTE]

========================================

For an external system, "api" at the end of the URL is optional.

For IZCentral, "api" is mandatory; also, IZCentral currently only works with HTTP API 1.3 (chosen from the Protocol Version dropdown).

========================================
[disc]
** Be sure to use the correct format:
{empty} +
http://<IP address of IZCentral or
{empty} +
3^rd^ party computer>:<port number>/api +
{empty} +
For example (port is typically 5801): +
http://195.163.2.73:5801/api
+
[IMPORTANT]

========================================

For secure communication, https can be used in the URL. In such a case, use the port registered for secure communication in IZCentral (for example, 11443). However, IZCentral must be configured to accept an encrypted connection (see the IZCentral User Guide for details - see <<s_Related-Documents>>).

========================================

[square]
* *Protocol Version* - The appropriate HTTP API version to use for your application.
+
[NOTE]

========================================

In INEX HTTP API version 1.5, the following items have not been implemented in {shortprodname}: +
camera_id and camera_name in the Upload Event command (images and lpr_results blocks) +
See the HTTP API 1.5 document - see <<s_Related-Documents>> .

========================================

[square]
* *Separated Images* - If checked, then images are sent in separate messages after the Event message; if unchecked, images and the Event are sent together in the Event message.
* *Send Images Data* (automatically checked for HTTP API 2.3 and above, as chosen from the Protocol Version dropdown) - If checked, then image data is sent as "data base64 encoded" inside the message; if unchecked, this field is not included in the message.
* *Offline Enabled* - Used if you want to enable offline saving of Events and images via HTTP. If you try to send an Event, but do not have a connection to the server, then this event will be put in an offline queue, and sent again when connection with the server is restored. Note that if you enable offline capabilities, you must configure the offline queue parameters (see <<s_Offline-Queue>>).
* *Send Triggers* (only enabled for HTTP API versions 1.3 to 1.6, as chosen from the Protocol Version dropdown) - If checked, then {shortprodname} will send Trigger Received messages to the server. The meaning of this command is: The camera has received a trigger to create an Event. The Event is being processed, and will be available soon.
* *Keep Alive Interval* (ms) - How often a status message is sent from {shortprodname} to the server
* *Event/Images Timeout* (ms) - If an Event or image message cannot be sent for this timeout period, then the event/image is put in the offline queue
* *Status Timeout* (ms) - If a status message cannot be sent to the server for this amount of time, {shortprodname} stops sending the message, and sends it again at the next Keep Alive Interval
* *Lane ID* - the Lane for which Events and statuses will be sent ("All" or a specific Lane)
* *After clicking the Save button, adding/editing an integration can take several seconds*
* *Each integration (channel) that appears in the table can be edited or deleted*
* *If you delete an entry, you will be asked to verify the deletion.*

[#s_Plate-Recognizer-Not-Used]

=== Plate Recognizer (Not Used)

Not used; do not enable

[#s_IZCloud-Integration]

=== IZCloud Integration

See the IZCloud document (see <<s_Related-Documents>>).

[#s_AMANO-Integration]

=== AMANO Integration

See the AMANO document (see <<s_Related-Documents>>).

[#s_TIBA-Integration]

=== TIBA Integration

See the TIBA document (see <<s_Related-Documents>>).

[#s_Designa-Integration]

=== Designa Integration

See separate document.

[#s_Offline-Queue]

=== Offline Queue
.Offline Queue Section
image::image16.png[image,width=528,height=158]

These parameters are currently used to configure offline Event storage for HTTP Integration (see <<s_HTTP-Integration>>).

[square]
* *Send Offline Events Every* - not currently used
* *Expiration Enabled* - Enables the following parameters:
[disc]
** *Offline Events Expire After* - If an Event was added to the offline queue because there was no connection with client, and the connection with the client was not restored within this time, the Event will be removed from the offline queue.
** *Send Offline Events After* - not currently used

[#s_Monitoring-IZMonitoring-Server-Integration]
=== Monitoring (IZMonitoring Server Integration)
.Monitoring Section
image::image17.png[image,width=493,height=152]

When Monitoring Integration (IZMonitoring Server Integration) is enabled, the following parameters appear:
[square]
* *URL* - URL of the IZMonitoring Server
* *Keep Alive Timeout (seconds)* - How often {shortprodname} sends Keep Alive messages. If the Server does not receive another Keep Alive message before this time expires, the overall status (severity) of the product (camera) will be set to "Offline" automatically by the Server.
* *Status Timeout (seconds)* - How often {shortprodname} sends a full status message to the Server.
* *Disk Critical Threshold -* When the percentage of used space on the disk (where the {shortprodname} storage is located) is above this number, then a critical disk status is sent to the Server.
* *Remember to click the Save button at the end of the Detector Configuration section after making changes.*

[#s_ZAP-Integration]

=== ZAP Integration
.ZAP Integration Section
image::image18.png[image,width=393,height=448]

[NOTE]

========================================

{shortprodname} can send Events to IZCentral or 3rd party systems using the INEX HTTP Protocol (see <<s_HTTP-Integration>>) and/or the INEX ZAP Protocol (see <<s_Related-Documents>>).

{shortprodname} can send Events via HTTP, and act as both a ZAP Server and ZAP Client - all simultaneously.

========================================

[square]
* *ZAP Server* - Check the box to have {shortprodname} act as a ZAP Server, to which ZAP Clients can connect (see the ZAP Protocol document for details - see <<s_Related-Documents>>):
[disc]
** *Ports* - Each Lane configured in {shortprodname} will automatically have its own row in the table. Each Lane should have a different port number.
** *ZAP Version* - ZAP communication protocol version. It is recommended to use version 4.4. The connected clients must use the same version.
** *Confidence Filter* - the confidence level below which Events are not sent
** *Keep Time (seconds)* - how long a Capture message is to be left in memory before it will be deleted (if a Keep message is not received)
** *Offline Enabled* - check this box to enable the ZAP offline queue
** *FTP Enabled (for ZAP Server) -* when a client is connected to {shortprodname} via ZAP, images can be sent to the client via FTP if this checkbox is checked.
[circle]
*** +++<u>+++FTP Server+++</u>+++ - the IP address of the FTP server
*** +++<u>+++FTP Port+++</u>+++ - the port on the FTP server listening for FTP messages
*** +++<u>+++FTP Folder+++</u>+++ - the folder path on the FTP server where the images will be stored
*** +++<u>+++FTP User+++</u>+++ - the username used to access the FTP server
*** +++<u>+++FTP Password+++</u>+++ - the password used to access the FTP server
*** +++<u>+++FTP Keep Alive Rate (seconds)+++</u>+++ - time (in seconds) between attempts to check that the connection with the FTP server is still alive
[square]
* *ZAP Client* - Check the box to have {shortprodname} act as a ZAP Client, which will connect to a ZAP Server (see the ZAP Protocol document for details - see <<s_Related-Documents>>). {empty} +
If you want {shortprodname} to work with IZCentral, {shortprodname} can only be working as a ZAP Client. In this mode, the {shortprodname} ZAP Client port must match the IZCentral ZAP port (see the IZCentral documentation - see <<s_Related-Documents>>).
[disc]
** *IP* - The IP address of the ZAP Server (to which {shortprodname} acting as a client should connect)
** *Port* - The port number of the ZAP Server
** *ZAP Version* - ZAP communication protocol version. It is recommended to use version 4.4. The server being connected to must use the same version.
** *Confidence Filter* - the confidence level below which Events are not sent
** *Keep Time (seconds)* - how long a Capture message is to be left in memory before it will be deleted (if a Keep message is not received)
** *Offline Enabled* - check this box to enable the ZAP offline queue
** *FTP Enabled (for ZAP Client) -* when {shortprodname} is connected to a ZAP server, images can be sent to the server via FTP if this checkbox is checked. (See the FTP Server items for the definition of the additional FTP parameters.)
[square]
* *Remember to click the Save button under the Detection Configuration section after changing these parameters.*

[#s_Direct-Trigger]

=== Direct Trigger
.Direct Trigger Section
image::image19.png[image,width=287,height=43]

The Direct Trigger settings are used in these operational modes: Triggered, Hybrid or NonTriggered With Trigger (see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>).

This parameter is used for Camera System models with external trigger input wires, such as the IZA500G. See your Camera System's Installation Guide for details.

A loop controller can provide trigger information to {shortprodname}. You can connect dry or wet contacts to the Camera System's trigger inputs. The rise and fall of the voltage levels at these inputs sends a trigger to {shortprodname} (see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>).

The "trigger time" used can be influenced by using the rising edge or falling edge of the pulse at the inputs to the Camera System. The Direct trigger mode options are (see <<f_Trigger-Sources-and-Sequence>>):

[square]
* +++<u>+++Disabled+++</u>+++ - Triggers will not be generated
* +++<u>+++OnRise+++</u>+++ - A trigger is generated when the voltage level sensed on the trigger wires moves from low to high
* +++<u>+++OnFall+++</u>+++ - A trigger is generated when the voltage level sensed on the trigger wires moves from high to low
* *Remember to click the Save button under the Detection Configuration section after changing these parameters.*

[#s_INEX-IO-Controller]

=== INEX I/O Controller


.INEX I/O Controller Section


image::image20.png[image,width=363,height=107]

The INEX I/O Controller settings are used in Triggered types of operational modes (for example Triggered, Hybrid or NonTriggered With Trigger). See <<s_Trigger-Sources-and-Trigger-Modes-Overview>> .

These parameters are used if triggers are sent via the LAN using an INEX IZIO Digital I/O Controller. See the IZIO Installation and User Guide for instructions on how to install and configure the IZIO (especially its IP address). See <<s_Related-Documents>> .

The IZIO provides trigger information to {shortprodname}. You can connect dry or wet contacts to the IZIO inputs. The rise and fall of the voltage levels at these inputs (such as pulses from loop controllers) are represented by a bit stream sent by the IZIO/ADAM to {shortprodname}. A change in state of an IZIO input causes the generation of a trigger (see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>).

In Server mode, advanced P2P mode support was added (available via the IZIO/ADAM configuration application); this enables the IZIO/ADAM to send state changes to multiple {shortprodname} instances. See the P2P document (see <<s_Related-Documents>>).

[square]
* *Pulling or Server* - how the digitized pulses are obtained by {shortprodname}
[disc]
** +++<u>+++Pulling+++</u>+++ - {shortprodname} will request state changes from the IZIO, sampled every 20 ms
** +++<u>+++Server+++</u>+++ - IZIO sends a notification of a state change to {shortprodname} (sampling is not needed)
[square]
* *Lane ID* - The Lane ID as defined in the lower part of the Settings tab
* *IP Address* - IZIO's IP address (configured via the IZIO configuration software. See the IZIO Guide for details (see <<s_Related-Documents>>).
* *Input* - The input channel on the IZIO to be polled/sampled
* *Trigger mode* - The "trigger time" used can be influenced by using the rising edge or falling edge of the pulse at the IO input of the IZIO/ADAM. The options are (see <<f_Trigger-Sources-and-Sequence>>):
[disc]
** +++<u>+++Disabled+++</u>+++ - Triggers will not be generated
** +++<u>+++OnRise+++</u>+++ - A trigger is generated when the voltage level sensed on the trigger wires moves from low to high
** +++<u>+++OnFall+++</u>+++ - A trigger is generated when the voltage level sensed on the trigger wires moves from high to low
[square]
* *Remember to click the Save button under the Detection Configuration section after changing these parameters.*

[#s_ICP-Integration-Not-Currently-Used]

=== ICP Integration (Not Currently Used)

See separate document.

[#s_IRD-Integration-Not-Currently-Used]

=== IRD Integration (Not Currently Used)

See separate document.

[#s_Journal-Optional-Local-Storage]

=== Journal (Optional Local Storage)


.Journal Section


image::image21.png[image,width=458,height=129]

The Journal (Local Storage) parameters determine if and how Events are stored on the local {shortprodname} computer disk (the parameters only appear if the disk is in use).

The Journal data is stored at: /mnt/data/journal

[square]
* *Cleanup Interval* - interval in milliseconds at which old Events are deleted in order to be within Max Count on Disk
* *Max Count on Disk* - Maximum number of Events that can be stored on the {shortprodname} computer's disk; this parameter should be left at its default

[#s_Events-Post-Processing]

=== Events Post Processing


.Events Post-Processing Section
image::image22.png[image,width=480,height=160]

[square]
* *Skip Empty Events* - When an Event does not include a plate recognition, it is ignored.
* *Combining Enabled* - used for combining Events with the same or similar recognition
[disc]
** *Send Timeout* - if another Event is received with the same or similar recognition results within this timeout, the two Events are merged into one Event
** *Lev Distance* - the maximum Levenshtein distance between the two plate reads for which the Events will be combined (see <<s_Detector-Configuration>> for a more detailed explanation of Levenshtein distance).
** *Align to Height* - when the LPR and OV images from the Events are merged, {shortprodname} selects the images in which the plate patch is closest to this percentage of the total height of the LPR/OV image. For example, if the images are 1000 pixels high, and this parameter is set to 75%, then {shortprodname} selects images in which the plate patch is closest (either above or below) a virtual line 750 pixels from the top of the image.

[#s_Trigger-Offset]

=== Trigger Offset

.Trigger Offset Section
image::image23.png[image,width=477,height=85]

The Trigger Offset affects all triggers (in all modes - see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>).

When Trigger Offset is enabled, the following parameter(s) appear:

[square]
* *Offset* (in milliseconds) - See <<s_Trigger-Sources-and-Trigger-Modes-Overview>>

The trigger command may arrive at a different time than actual trigger's (physical) arrival time (see <<f_Trigger-Sources-and-Sequence>>). For example, there is often a delay between the time a vehicle passes over an inductive loop, and the time the loop controller generates a pulse. This latency can be compensated for by an "offset".

[#s_Detector-Configuration]

=== Detector Configuration


.Detector Configuration Section


image::image24.png[image,width=433,height=472]

Plate recognition is done in 3 stages:

[square]
* The position of the license plate is determined in each incoming frame (from each camera)
* Characters from each license plate image are read and recognized
* All of the reads of each plate are grouped to create LPR Events

The following parameters are used to configure these processes. *Remember to click the Save button at the end of this section after changing these parameters:*
[square]
* *Mode* - see <<s_Trigger-Sources-and-Trigger-Modes-Overview>> . Note that parameters may appear or be hidden, depending on the chosen Mode.
* *Region* - Region for which characters on the plate will be recognized. Select from the following options:
[disc]
** +++<u>+++Australia+++</u>+++
** +++<u>+++Canada/North America+++</u>+++ - same as North America LPR, with a different state recognition model that includes Canadian states.
** +++<u>+++Europe+++</u>+++
** +++<u>+++Israel+++</u>+++
** +++<u>+++North America+++</u>+++ - general recognition that includes all U.S.A. states
** +++<u>+++North America (OR)+++</u>+++ - same as North America, with the addition of syntax checking (against predefined patterns of characters) for Oregon state
[square]
* *State* - The State within the selected Region for which characters on the plate will be recognized. You can also select "ALL"; this indicates that the recognition engine will use a general model for this Region.
* *Skip stacked characters (only for Regions with stacked character plates)* - When enabled, causes stacked characters to be excluded from the plate read.
* *Detector confidence threshold* - The minimum Detector confidence that this rectangle is a license plate. If a read is at or above this threshold, the image is sent on for plate reading (plate character) processing.
* *Plate reader confidence threshold* - The minimum Plate Reader confidence that the characters read are correct. If a read is at or above this threshold, an Event is created. If more than one camera is capturing images from a lane, the image with the highest confidence among the cameras is used.
* *Plate reader regexp filter* - Only license plate reads meeting these regular expression filter criteria will have Events created for them. Typically, the default should be used (.* = allow all reads).
* *Min plate read count* - To increase read accuracy, plates are read from more than one video frame. If the same plate read results match on at least this number of frames, then the Event will be created. +
For slow-moving traffic, this parameter should be increased. +
For faster traffic, you will only be able to set it to a small number of reads.

* *Wait before event emit, ms* - (affects results in NonTriggered or Hybrid modes) +
The minimum time from the first plate read until the time the Event will be built (emitted) - which can result in a greater number of frames used than the "Min plate read count" parameter. You may want to get LPR results with better confidence by increasing this number. {shortprodname} will wait for more correct reads before the Event is built (see <<f_Illustration-of-Wait-Before-Event-Emit>>). +
As a vehicle approaches a camera, waiting longer will usually (depending on road geometry) result in images of the plate getting larger and easier to read accurately. +
Note that in hybrid mode, it is recommended to set this parameter greater than 0. Setting this parameter to 0 will result in lower read confidence, since the trigger and the first read will occur close together.

[#f_Illustration-of-Wait-Before-Event-Emit]

.Illustration of Wait Before Event Emit

image::image25.png[image,width=504,height=186]
[square]
* *LP forget interval, ms* - {shortprodname} may not have been able to read a plate over the course of several frames, which appear between two groups of frames with correct reads. +
If the size of this "hole" is large, then the vehicle has probably disappeared but then returned. This value controls whether or not to consider the two sequences of captures to be a single Event, or two separate Events.

.Illustration of LP Forget Interval

image::image26.png[image,width=507,height=97]

[square]
* *Max Levenshtein distance* - Different reads of the same plate may not be identical due to shadows, sunlight, blurred images, etc. However, we want to minimize these effects by treating slightly different reads as the same result. We allow a maximum "distance" (number of changes required to match two strings) between plate reads in an Event. If the distance is less than or equal to this parameter, then the comparison is considered to be a valid match for the Event.
* *JPEG frame quality, 0-100 (0=no frame sent)* - The Overview image JPEG frame quality used to send images to IZCentral or a 3rd party system.
* *JPEG plate quality, 0-100 (0=no frame sent)* - The LPR image JPEG frame quality used to send images to IZCentral or a 3rd party system.
* *Include all images (for "Triggered" and "NonTriggered With Trigger" modes only)* - Enables display in Live tab, and sending of +++<u>+++all+++</u>+++ images (including pre- and post-trigger frames) - not only the "best" ones that were used for plate recognition
* *Image Resize* - when enabled, and the Event confidence is equal or higher than the Resize Confidence parameter, then each LPR and OV image is resized according to the Image Width (and the height is resized proportionally).
[disc]
** *Image Width* - the resize width
** *Resize Confidence* - the Event confidence threshold for enabling resizing
[square]
* *Two Line Plate -* When enabled, invokes the capability to recognize two-line plates (in which the license plate number consists of two rows).
[disc]
** *Threshold* - if the ratio of the width of the plate to its height is less than this threshold, then the plate very likely has two lines. The plate read will be the lower number added to the upper number.
** *Padding Width* (%) - the percentage of the width of the plate to be removed from each side of the upper and lower images before putting the two numbers together. This eliminates empty space before the composite number is sent for recognition.
** *Padding Height* (%) - the percentage of the height of the plate
[circle]
*** This percentage is measured from the top, to determine where to crop the plate to determine how to extract the upper number's image
*** This same percentage is measured from the bottom, to determine where to crop the plate to determine how to extract the lower number's image
[square]
* *Vehicle Class Detection -* enables/disables vehicle class detection (car, bus, etc.). This item can be shown on the Live tab using the multi-line menu at the upper right of the screen (see <<s_Live-Journal-Tab>>).
* *State recognition* - Enables state recognition (an Overview camera must have been defined and configured)
* *Send default state* *(only if State recognition* *is enabled) -* If no State was recognized, checking this box enables sending the Default State Value in the HTTP message for the Event as per the following additional parameters that appear: (If unchecked, no State field will be sent in the message.)
[disc]
** *Default state value* - The default value to be sent in the HTTP message for the Event if no State was recognized.
** *State confidence threshold* - The minimum confidence percentage for State recognition
[square]
* *LPR Stub Enabled* -If a plate was detected, but without a plate read, {shortprodname} sends the text defined in the LPR Stub text box, along with the LPR Stub Confidence value:
[disc]
** *LPR Stub* - for example, "NOREAD"
** *LPR Stub Confidence* - for example, 0
[square]
* *Hybrid Pre Time (for Hybrid mode only)* -Time in milliseconds before the trigger to search for the closest Event to the trigger (see <<f_Illustration-of-Hybrid-Pre-Post-Time>>)
* *Hybrid Post Time (for Hybrid mode only)* - Time in milliseconds after the trigger to search for the closest Event to the trigger (see <<f_Illustration-of-Hybrid-Pre-Post-Time>>)

[#f_Illustration-of-Hybrid-Pre-Post-Time]

.Illustration of Hybrid Pre/Post Time

image::image27.png[image,width=624,height=170]

[disc]
** Trigger 1 will be checked against the Hybrid Pre/Post time and use the closest Event - Event 1 or Event 2 (most likely). Note that Trigger 1 is closest to +++<u>+++Event+++</u>+++ 2, even though it is closer to the +++<u>+++best LPR frame+++</u>+++ in Event 1.
** Trigger 2 will use Event 2.
** Trigger 3 will wait for a new Event. If a new Event does not arrive within the Hybrid Post Time, a trigger Event will be created, without an LPR read, but with associated images and a timestamp.

[#s_Lanes]

=== Lanes


.Lanes Section


image::image28.png[image,width=617,height=87]

[square]
* Actions:
[disc]
** +++<u>+++Edit+++</u>+++ - edit the Lane's parameters
** +++<u>+++Delete+++</u>+++ - delete the Lane (a warning will be displayed)
** +++<u>+++Trigger+++</u>+++ - send a software trigger immediately to {shortprodname} (works in all modes except NonTriggered)
+
[NOTE]

========================================

Each Lane number must be unique in the overall IZ ALPR system.

The images from all cameras capturing the same physical lane will be combined into a single Event.

Each "Lane" is actually a virtual Lane. For example, if you have two Camera Systems capturing the same physical lane, you will need to create two different "Lanes", and associate each Camera System's cameras with a different "Lane".

========================================

+
.Add/Edit Lane Dialog

image::image29.png[image,width=265,height=151]

[square]
* *ID* (required) - The identification number of the lane to be captured by the cameras. This number will appear associated with Events in the Live tab (see <<s_Live-Journal-Tab>>).
* *Name* (required) - The name of the Lane as it will appear in the GUI. This name will also be sent in HTTP and ZAP messages.

+

[NOTE]

========================================

If you have upgraded from a previous {shortprodname} version in which only Lane IDs were specified, Lane names will be automatically assigned the word "Lane" plus the Lane ID.

========================================

[square]
* *Avg Speed (for DOT cameras only)* - The average vehicle speed expected in this Lane
* *Distance* *(for DOT cameras only)* - The distance between the trigger device and the camera
* *Location (for ALPR cameras only)* - Select one of the following options:
[disc]
** *Unknown* -The camera's position relative to vehicles is unknown.
** *Front* -the camera in this Lane is capturing images from the front of vehicles
** *Rear* - the camera in this Lane is capturing images from the rear of vehicles
[square]
* *Ignore Opposite Direction* - if enabled, then all Events for vehicles moving in the direction opposite to the direction arrow in the Calibration tab will be ignored (see <<s_Calibration-Tab>>). Note that you can add a Direction column to the Live tab using the multi-line menu at the upper right of the screen (see <<s_Live-Journal-Tab>>).

[#s_Cameras]

=== Cameras


.Cameras Section


image::image30.png[image,width=695,height=112]

[NOTE]

========================================

If you are using an IZMobileLPI system, contact INEX for details on how to set the camera parameters.

========================================

[square]
* Actions:
[disc]
** +++<u>+++Edit+++</u>+++ - edit the camera's parameters (see <<f_Add-Edit-Camera-Dialog>>)
** +++<u>+++Delete+++</u>+++ - delete the camera (a warning will be displayed)
[square]
* *Camera table headers:* Camera ID, Lane ID, Name, URL, Type (as configured when the camera was added)
* *Image* - Thumbnail image from a recent camera image

+

[WARNING]

========================================

If you add a camera, or edit a camera's parameters and click the Save button in this dialog (even if you did not change the URL), you may see a warning icon in the Image column. The reappearance of the image indicates that the core software has restarted, and Events will resume being captured and displayed in the Live tab, with the following changes:

* The Transaction ID will restart at 1 for that camera. +
* The history of previous Events for that camera will be cleared

========================================

[square]
* *Add Camera* (button at end of Cameras section):
+

[#f_Add-Edit-Camera-Dialog]

.Add/Edit Camera Dialog

image::image31.png[image,width=230,height=272]

[disc]
** *Lane ID* - The identification number of the lane being captured by the camera(s). Select a Lane number you defined (see <<s_Lanes>>). This number will appear associated with Events in the Live tab (see <<s_Live-Journal-Tab>>).

+

[NOTE]

========================================

The images from all cameras capturing the same physical lane will be combined into a single Event.

Using the same Lane ID for different cameras (even the LPR and OV cameras within the same Camera System) will combine the reads into one Event (see <<s_Lanes>>). You may even be able to improve read accuracy by changing the zoom to have one camera "see" closer than the other one.

You could also position cameras to be in different positions (front/rear as in a toll plaza).

========================================

[disc]
** *Camera ID* - For internal use; should be unique in the overall IZ ALPR system
** *Name* - Camera name for internal use; should be unique in the overall IZ ALPR system
** *URL* - RTSP or HTTP URL:
[circle]
*** RTSP stream URL example: +
rtsp://<camera IP address>/cam0_0
*** HTTP URL example: +
http:// <camera IP address>
[disc]
** *Type* - Type of camera (LPR or View); used for integration with IZCentral
** *Trigger Pre* (used in Triggered mode types only) - Number of frames to be included in the set of frames used to build an Event - +++<u>+++before+++</u>+++ the trigger occurs (see <<f_Trigger-Sources-and-Sequence>>).
** *Trigger Post* (used in Triggered mode types only) - Number of frames to be included in the set of frames used to build an Event - +++<u>+++after+++</u>+++ the trigger occurs (see <<f_Trigger-Sources-and-Sequence>>).

[#s_Live-Journal-Tab]

== Live (Journal) Tab


.Live (Journal) Tab with Row Selected


image::image32.png[image,width=554,height=243]

The Live tab displays Events and other data about each Event.

[NOTE]

========================================

The Events displayed in the Live tab are being simultaneously sent via the protocols you selected in the Settings tab.

You should see that Events are being generated for each vehicle passing each camera, with sufficient recognition accuracy and confidence. If not, see <<s_Troubleshooting>> for troubleshooting tips.

If you return to the Live tab from another tab, the large picture returns to the LPR (black and white) camera image.

DOT (USDOT number image capture) cameras generate Events, but without LPR reads.

========================================

[square]
* Each row includes (additional items can be added from the multi-line menu icon > Configure Journal selection - continue reading):
[disc]
** +++<u>+++Transaction (Event) ID+++</u>+++. Note that each camera has its own Transaction ID sequence, so the same IDs may be used for different cameras.
** +++<u>+++Lane Name+++</u>+++ - Lane name as configured for the camera(s) viewing this lane in the Settings tab - see <<s_Lanes>>
** +++<u>+++Date and time+++</u>+++ when the Event was recorded
** +++<u>+++License Plate number+++</u>+++ (LPR)
** +++<u>+++Recognition confidence+++</u>+++, expressed as a percentage
** To add columns to the Live (and Search) tab displays:
[circle]
*** Click on the multi-line menu icon at the upper right of the {shortprodname} screen
*** Select "Configure Journal" +

.Configure Journal (Multi-line Menu)

image::image33.png[image,width=136,height=113]


[circle]
*** Select the additional columns to display, such as: +++<u>+++State+++</u>+++ (state displayed on plate), +++<u>+++State Confidence+++</u>+++ (confidence that the state has been recognized accurately), +++<u>+++Class+++</u>+++ (vehicle class, such as car or truck), +++<u>+++Class Confidence+++</u>+++ (confidence that the class has been recognized accurately) and +++<u>+++Direction+++</u>+++ (direction vehicle was traveling - forward or backward - according to the direction arrow configured in the Calibration tab - see <<s_Calibration-Tab>>). (These additional columns will also appear on the Search tab - see <<s_Search-Tab>>)
[square]
* Pause/Run mode:
[disc]
** Pause the grid display by clicking on a row, or by using the pause button in the middle of the controls under the large image (). You can also click on the large image to toggle between Pause and Run mode. This is useful if you want to examine a specific Event.
** You can also use these controls to move through the grid (next/previous Event, or start/end of Events).
** Start the display running in real-time again using the Run button () or by clicking on the large image. This will refresh the display, and resume displaying Events, starting from the 20 most recent Events.
+

[NOTE]

========================================

{shortprodname} is continually recording and saving (Journal) Events. The Events are added to the Live display (Running mode operation) until the display is paused. Even when you pause the Live display, {shortprodname} continues to record Events - and can display up to a maximum of 20 recent Events.

As you Pause/Run the Live grid, you may see momentary icons ( or ) appearing in the middle of the large image pane to indicate the mode.

========================================

+

[square]
* The text below the Pause/Run controls displays a summary of the Event's information.
* The thumbnail images below the larger image pane display the overview and plate patch images from each camera. Click on one of the thumbnail images to display it in the larger image pane.

+

[NOTE]

========================================

If both cameras in a Camera System were set to view the same lane, but one of the cameras (usually the color Overview camera) failed to capture the license plate properly, you will only see 3 thumbnails instead of 4.

If you are using a camera with one sensor (such as the IZ600F), you will see 2 thumbnails - one for the LPR/OV image, and one for the plate patch.

========================================

+

[square]
* Zoom in on an area of interest in the large image (requires a mouse with a wheel):
[disc]
** Pause the grid
** Hover (do not click) over the area of interest; the cursor will change to a magnifying glass.
** Mouse wheel up a little at a time to enlarge the image
** As the image enlarges, you may need to readjust the cursor position to re-focus on the area of interest
[square]
* To save images, right-click on the large image pane, and save the image

[#s_Search-Tab]

== Search Tab


.Search Tab


image::image34.png[image,width=645,height=307]

The Search tab enables you to search for Event records stored in the {shortprodname} database.

[NOTE]

========================================

The same columns that were added to the Live display (using the multi-line menu at the upper right of the screen) will also appear in the Search display (see <<s_Live-Journal-Tab>>).

========================================

[#s_Search-Tab-Page-Controls]

=== Search Tab: Page Controls

Page controls are located at the upper right of the records grid:


.Search Tab: Page Controls


image::image35.png[image,width=424,height=193]

[#s_Search-Tab-Filters]

=== Search Tab: Filters

Filter boxes are located at the top of each column; you can click on the question mark icons to show explanations of what you can enter in each filter box.

[IMPORTANT]

========================================

After applying filters, remember that you will need to use the page controls to see all of the filtered records. For example, if there are 85 results, but you configured the grid to display 20 records per page, you must use the page controls to see the filtered records appearing on each page.

========================================

[square]

* *Numeric filters* (Event ID, Confidences) - Enter a specific number (example '30'), a number and a '>' symbol (example '>30') or a number and a '<' symbol (example '<30')

* *Lane Name* - Select All, or a specific lane

* *Time* - Click in the filter box to display a date/time selection popup. Uncheck the check box to clear the filter (see <<f_Search-Tab-Time-Filter-Selection-Popup>>).

+

[#f_Search-Tab-Time-Filter-Selection-Popup]


.Search Tab: Time Filter Selection Popup

image::image36.png[image,width=317,height=308]


+

[disc]

** Use the buttons at the top of the From/To sections to move between months

** Use the calendar grids to select dates

** Use the sliders to specify time

** Click the Now button to select the current time/date

[square]

* *Text filters* (LPR, State, Class) - Enter characters to find within the strings. For example, KZ will find **+++<u>+++KZ+++</u>+++**R3791 and J**+++<u>+++KZ+++</u>+++**0714.

* *Direction* - Select All, Forward, (Unknown) or Backward

[#s_Calibration-Tab]

== Calibration Tab


.Calibration Tab


image::image37.png[image,width=624,height=313]

. When you see a vehicle at a typical capture position on the video, click on the video to pause it.

. It is recommended to use the view called "Draw image by maintaining aspect ratio (two-headed arrow)". You select this view by clicking on the right-most button at the upper left of the screen: *_\\{Zvulun: inline graphic}_* image::image38.png[image,width=21,height=15]

. Select a camera from the dropdown list (LPR or OV).

. The Frame Width (horizontal) and Frame Height (vertical) are displayed at the lower left, and are set automatically according to the Camera's hardware configuration. See your Camera's Installation and Calibration Guide.

. The Frame Timestamp at the lower left displays the date and time that the image is being taken/was taken by the camera.

. Aim the camera using the mounting bracket's adjustment hardware (see <<f_Pan-Tilt-Roll-Angle-Adjustments>>).

.. *Pan*: Adjust the Pan so that the image of the license plate is in the horizontal middle of the Field of View.

.. *Tilt:* Adjust the Tilt so that the image of every expected plate position (depending on the vehicle type, such as passenger cars, jeeps, trucks, etc.) will be in the middle of the screen (from top to bottom).

.. *Roll*: Adjust the Roll so the license plate's image is horizontally straight, parallel to the ground (not tilted to one side).

+

[#f_Pan-Tilt-Roll-Angle-Adjustments]


.Pan/Tilt/Roll (Angle) Adjustments

image::image39.png[image,width=311,height=186]


. When the correct position is achieved, make a preliminary tightening of the mounting screws.

. Define the Region of Interest (*ROI*) by dragging on the corners (vertices) of the trapezoidal region. For optimum recognition accuracy, the ROI should be large enough to capture the region where plates could be found in images.

+

[NOTE]

========================================

The following settings for the LPR and OV cameras are saved separately. For example, you may want a Region of Interest that is different for each camera.

========================================

+

. Define the *Plate Width Min*: Events will only be created for plate reads whose width is greater than or equal to this parameter. It is recommended to enter 150 in the *Plate Width Min* text box. +
This parameter can also be configured by dragging the small circle on the horizontal line on the Calibration tab (expressed in pixels). +
This parameter can be used to ignore small plate reads. For example, if the image was taken when a vehicle is too far away, the characters are too small to be read - even by a human.

. Define the *Plate Width Max*: Events will only be created for plate reads whose width is less than or equal to this parameter. It is recommended to enter approximately 350 in the *Plate Width Max* text box. +
+ +
This parameter can also be configured by dragging the large circle on the horizontal line on the Calibration tab (expressed in pixels). +
+ +
This parameter can be used to prevent false reads, such as large numbers on trucks.

. Use the zoom and focus buttons to adjust the view of the video until the width of the plate is 150 pixels, and its plate image is clear and sharp. (The surrounding items, such as the vehicle body, do not need to be as sharp as the plate.)

[IMPORTANT]

========================================

There is a delay between a click of a zoom/focus button and when you see the effect on the screen. Be sure to wait until you see the change on the screen before clicking the button again. Clicking the button multiple times will cause you to "overshoot" the desired zoom/focus.

As you adjust the zoom and focus, you may need to reposition the camera in order to get the image of the plate back to the desired position.

========================================

. *Direction (red arrow on video):* drag the head of the arrow around to point to the angle at which you expect vehicles to be moving**.** (The vehicle's direction is also sent to the IZCloud as part of an Event.) You can add a Direction column to the Live tab using the multi-line menu at the upper right of the screen (see <<s_Live-Journal-Tab>>). +
+ +
You can set the "Ignore Opposite Direction" parameter in the Lanes section to ignore all Events for vehicles moving in the direction opposite to the direction arrow in the Calibration tab (see <<s_Lanes>>).

. When you have finished, click the *Save* button. Wait several seconds for the display to refresh automatically, which indicates that the {shortprodname} recognition software is running again with the updated parameters.

. When the correct position is achieved, make a final tightening of the mounting hardware.

. Repeat these steps for the other camera.

[#s_System-Info-Tab]

== System Info Tab


.System Info Tab

image::image40.png[image,width=316,height=308]


[NOTE]

========================================

Some System Info sections may not appear depending on your version of {shortprodname}.

========================================

[#s_System-Info-Tab-System-Info-Section]

=== System Info Tab: System Info Section

This section provides the same information as in the upper right corner of the same Settings tab, namely the model, part number and serial number of the camera(s) {shortprodname} is communicating with.

[#s_System-Info-Tab-Firmware-Section]

=== System Info Tab: Firmware Section

[square]

* Firmware Version - the firmware version of the IZIC board (proprietary INEX electronics) in the Camera System/DPU

* New Firmware - enables you to update new firmware in the IZIC board

[disc]

** Choose File - click this button to browse for the firmware file

** Update Firmware - click this button to update the firmware using the file you chose

[#s_System-Info-Tab-Night-Mode-Section-for-Specific-Camera-Models-Only]

=== System Info Tab: Night Mode Section (for Specific Camera Models Only)

These parameters affect how {shortprodname} controls an external illuminator:

[square]

* *Night Mode*

[disc]

** +++<u>+++Disable+++</u>+++ - never trigger the illuminator

** +++<u>+++Enable+++</u>+++ - camera and external illuminator behavior are optimized for night-time recognition. Recommended use is for calibration.

[circle]

*** *OV LED Intensity* - Relative intensity of the built-in white LEDs, expressed as a percentage of the maximum possible intensity

*** *Illuminator Intensity* - (for IZS illuminators, synchronized with the Overview camera) Relative intensity of an external illuminator's LEDs, expressed as a percentage of the maximum possible intensity

[disc]

** +++<u>+++Auto+++</u>+++ - automatically senses day/night, in order to decide whether to trigger an external illuminator, according to the Camera System's location (as defined by the Latitude and Longitude parameters). For the Auto mode, additional parameters appear:

+

[NOTE]

========================================

Latitude and Longitude are user-entered coordinates; determine them using Google maps, by clicking on the location where the Camera System will be installed (remember to put in a minus sign as needed)

========================================

+

[circle]

*** *Latitude* - latitude coordinate of Camera System's location

*** *Longitude* - longitude coordinate of Camera System's location

*** *Post-Sunrise Offset* - time after actual sunrise to be considered as the start of the day

*** *Pre-Sunset Offset* -time before actual sunset to be considered the end of the day

[square]

* *Remember to click the Save button at the end of this section after making changes.*

[#s_System-Info-Tab-LPR-LED]

=== System Info Tab: LPR LED

These parameters enable you to control the camera's built-in IR LEDs.

[square]

* Mode

** *Off* - LEDs off

** *Multi-flash* - each frame is illuminated with a different light intensity

** *Anti-flickering* - reduces the visible flickering of the built-in IR LED illumination by disabling multi-flash mode and adjusting flash frequency

[square]

* *Intensity* - light intensity in percent, where 0 is no light, and 100 is maximum light

[#s_Troubleshooting]

== Troubleshooting

[NOTE]

========================================

For details about items in the following list related to hardware or configuration, see your camera's Installation and Calibration Guide.

========================================


.Troubleshooting


[width="100%",cols="35%,65%",options="header",]
|===
|Symptom |Possible Solution
|Thumbnails in Settings tab, in the Camera section at bottom have been replaced by red exclamation points and/or +
The Live tab and Search tab are empty (no Events are detected) a|
* Verify that each camera's IP address in the Camera System (or connected to the DPU), and the {shortprodname} computer's IP address are all on the same subnet.

* Verify that stable power at the correct level is being supplied to the cameras, even when under a heavy processing load.

* Verify that the IP address(es) configured in {shortprodname} match the IP addresses that you configured in the camera(s). See <<s_Cameras>> .

|Recognition rates are low a|
* On the Calibration tab, increase the size of the Region of Interest (ROI) - it may be too small to capture plates with high confidence

* On the Calibration tab, try to reduce the Plate Width Min and increase the Plate Width Max

Examine the video from the Camera on the Calibration tab:

* If all license plates are not fully visible, re-aim the Camera so that the Camera's field of view fully covers the capture zone. For a more precise adjustment, verify that the license plate's images are as close to the middle of the video display as possible.

* If the images are spotted, remove dirt and dust from the front window of the Camera System with a soft cloth and mild soap

* If the images are not sharp, adjust the zoom and focus of the camera

|===

== Appendix A - Document Change History

[width="100%",cols="16%,18%,66%",options="header",]
|===
|Version |Date |Change
|1.00 |Aug. 25, 2020 |Initial version
|1.10 |Sep. 13, 2020 a|
Version for Release 1.7. Changes from Release 1.6 are:

* Added new Setting parameter: JPEG frame quality, 0-100 (0=no frame sent)
* Added new Setting parameter: JPEG plate quality, 0-100
* New Detector option "Precise license plate detector"
* Cursor changes to magnifying glass when hovering over large Journal image

|1.20 |Dec. 6, 2020 a|
Version for Release 1.9. Changes from Release 1.7 are:

* Added specific version number (1.9) to Applicability section.
* Improved camera images in typical system figures
* Updated Settings screen shots
* Added explanations of new parameters
* Removed all options from the Detector parameter except for Precise License Plate Detector
* Added new choices in GUI for different operational modes
* Added pictures to illustrate operational and triggering modes
* Changed thumbnail description at bottom of Settings tab to say "Thumbnail image from a recent camera image" instead of from a recent Event

|1.25 |Jan. 11, 2021 a|
Updates for software version 1.9.13:

* Updated Settings screen - new layout, and less Save buttons (each remaining Save button has a different functionality)
* New sections on Settings screen - software version and camera information, and Lanes section on Settings screen - a list of Lanes can be defined
* Camera Add/Edit dialog has changed since Lanes are defined in the new Lanes section
* New screen shot for IZ Discovery - First column changed from Product to Serial Number
* Added notes reminding user that some settings may be different for IZMobileLPI configuration

|1.30 |Mar. 3, 2021 a|
Updates for software version 1.9.25

* Support for new version of IZ Discovery utility; new IZ Discovery screen capture
* HTTP API 2.3 support (selectable from a new dropdown in the Settings screen), including triggering, was implemented - you can now trigger Events using the HTTP API protocol by sending the trigger from an external application to {shortprodname} - see the HTTP API documentation. HTTP API 2.3 also supports the Communication options of Separated Images and Send Images Data.
* New screen capture taken for Settings screen and associated dialogs

|1.31 |Mar. 11, 2021 a|
* Improved quality of IZ Discovery screen shots

|1.40 |Apr. 19, 2021 a|
* Removed cameras and IZODPU-G from Related Documents
* Updated HTTP API document file format in Related Documents
* Changed IZODPU-G to DPU where appropriate, since there are other DPUs that run {shortprodname} software
* Changed screen shot of logging out, since multi-line menu icon at upper right now has an additional option
* Added new screen shots for Settings and Journal tabs
* Added screen shots and explanations for new parameters and new order on Settings tab
* Changed Applicability to 1.11.x

|1.41 |Apr. 29, 2021 a|
* Added paragraph to legal disclaimer referring to internet security risks

|1.45 |May 27, 2021 a|
Updates for version 1.13.13 of the software:

* Updated glossary
* Removed wiring diagrams (due to constant change)
* Made minor edits to IZ Discovery section
* Added new parameters to Detector Configuration: skip stacked characters, state recognition, send default state, default state value, state confidence threshold
* New calibration tab and parameters
* Updated explanation of Trigger 3 in Hybrid Pre/Post time
* Expanded troubleshooting table

|1.46 |June 1, 2021 a|
* Changed Journal Settings header to Journal (Optional Local Storage)
* Added text to Journal Settings text: (the parameters only appear if the disk is in use)

|1.47 |June 13, 2021 a|
Updates for latest production software release - 1.13.17:

* {shortprodname} GUI can now be accessed using https at the start of the URL
* https can now be used in the HTTP Integration URL
* HTTP API 1.4 and 1.5 are now supported (and appear in the HTTP Integration Add/Edit dialog (Protocol Version dropdown)
* User can choose the Lane (or All Lanes) for which Events and statuses will be sent in the HTTP Integration Add/Edit dialog
* Plate Width Min and Plate Width Max were moved from Detector Configuration section in Settings tab to the Calibration tab

|1.48 |July 13, 2021 a|
* Changed name and filename of document, and name of software in document - to reflect new name for this version of {shortprodname} which is "{shortprodname} ALPR"

|1.50 |Jan. 9, 2022 a|
Updates for latest production software release - 1.15.59; changes from 1.13.17 include:

* For new functionality and parameter changes, see the {docproductname} Release Notes
* Expanded Direct Trigger and INEX I/O Controller explanations
* Moved Trigger and mode diagrams to separate section earlier in document
* Updated Hybrid mode's 3rd trigger explanation
* Expanded Lanes explanation - how to manage multiple cameras on the same physical lane
* Added Journal explanation - "You can also click on the large image to toggle between Pause and Run mode"
* Calibration tab description updated for new functionality
* Added section for new System Info tab

|1.51 |Jan. 11, 2022 a|
* Corrected spelling and typographical errors

|1.52 |Jan. 23, 2022 a|
* Added new parameters to Night Mode section on System Info tab; replaced screen shot
* Replaced screen shot of Software Version and Camera Information

|1.60 |Oct. 27, 2022 a|
* Updates for latest production software release - 1.15.64.31
* Chrome added as a possible browser for running {shortprodname}
* Screen shots updated/added to reflect new features
* Network Settings - DNS1/2 parameters added
* HTTP Integration - added the following parameters: Offline Enabled, Keep Alive Interval, Event/Images Timeout and Status Timeout; also, the Separated Images option now works with all protocol versions, not just 2.3 and above.
* New configuration section - Plate Recognizer
* IZCloud Integration - added Remote URL field to Lanes table; updated GPIO explanation to match Remote URL explanation
* New configuration section - Designa Integration
* New configuration section - Offline Queue
* ICP Integration - cannot be used in 1.15.64.31
* IRD Integration - cannot be used in 1.15.64.31
* New configuration section - Events Post-Processing
* Detector Configuration - new parameters: Image Resize, Two Line Plate, Vehicle Class Detection
* Lanes - new parameter: Ignore Opposite Direction
* Journal tab renamed to be "Live" tab; new columns can now be added: Class, Class Confidence and Direction
* New tab added: Search

|1.61 |Oct. 30, 2022 a|
* Updated document change history to show that ICP and IRD integration cannot be used in 1.15.64.31.

|1.65 |Feb. 7, 2023 a|
Updates for releases 1.15.64.32 to 1.15.64.48:

* Changed format to only include details of core Settings sections; customer- and integration-specific sections will be described in separate documents
* Users can access the Flexwatch sensor configuration application by adding an IE Tab extension to Chrome
* New screen shot of Software Version and Camera Information on the Settings tab
* New screen shot for Adding an HTTP Integration to show new Send Triggers check box, plus explanation of Send Triggers (HTTP API Trigger Received command)
* Plate Recognizer Settings are not used.
* AMANO Integration section added in Settings tab; separate document referenced
* IZCloud Integration - separate document created and referenced
* INEX I/O Controller section: In Server mode, advanced P2P mode support was added (available via the IZIO/ADAM configuration application); enables IZIO/ADAM to send to multiple {shortprodname} instances
* LPR LED section was added in System Info tab
* New screen shot of System Info tab
* The Configure Journal selection (available from the three-line menu) that enables you add columns to the Live data grid - also affects the Search data grid
* Support of RTSP protocol for cameras (can enter RTSP URL or HTTP URL when adding a camera); deleted phrase of: "(cam0_0 indicates that the primary stream should be used)"

|1.66 |Feb. 21, 2023 a|
Updates for release 1.15.64.54:

* New screen shot for System Info; added note that some System Info sections may not appear depending on your version of {shortprodname}
* TIBA Integration section added in Settings tab; separate document referenced
* New parameters added in ZAP Integration section for both Server and Client
* Added text explaining how to configure {shortprodname} acting as a ZAP Client can communicate with IZCentral

|1.67 |Mar. 23, 2023 a|
* New screen shot for updated Date and Time section on Settings tab; the interval at which {shortprodname} polls for the date and time is now selected from discrete values instead of a number of milliseconds
* Included missing State dropdown explanation in Detector Configuration section on Settings tab; added new "ALL" selection
* Due to the updated software version number, new screen shots were taken for the "Software Version and Camera Information" section on the Settings tab, and the complete System Info tab
* Updated some of the IZ Discovery wording to match other documents
* Clarified which browser to use when running {shortprodname}

|1.68 |Apr. 16, 2023 a|
* Preparation for online conversion: Put rectangle around screen shot pictures in PPT - instead of using Word borders

|1.69 |Apr. 16, 2023 a|
* Added document reference to {shortprodname} Video Analytics Data Sheet

|1.70 |May 17, 2023 a|
* Corrections discovered during conversion to online version (for example, cross-references)

|--- |--- a|
* From this point on, see the GitHub commit history comments

|===
