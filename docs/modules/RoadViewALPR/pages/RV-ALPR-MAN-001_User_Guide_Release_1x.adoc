:docproductname: RoadView ALPR
:shortprodname: RoadView

// set attribute (by uncommenting the line)
// used to determine which text/links to sections
// outside partials - should be used in partials
// see the playbook for full list

:xref-type-RoadView:
:layout-type-userguide:

//enable the TOC to be placed in a specific position
:toc: macro

= {docproductname} User Guide

//xref:RoadViewALPR:DocList.adoc[<- Back to {shortprodname} Documents]

//image:ROOT:image$INEX_DataSheet_Logo_With_Line.png[INEX Logo,align=right]

//!sectnum momentarily stops section numbering
:!sectnums:

// This "invisible" text helps lunr search put this page
// at the top of the results list when searching
// for a specific product name
// BUT TRY THE SEARCH WITHOUT IT, SINCE IT
// APPEARS IN GRAY ON A PDF/PRINTOUT
// [.white]#{shortprodname}#

// discrete removes these headers from the TOC
[discrete]
== Advanced ALPR Software
Release 1.x

// restore section numbering from here on
:sectnums: all

// place the TOC in this specific position (capability enabled by :toc: macro at start
// of file
._Click to show the Table of Contents_
[%collapsible]
====

toc::[]

====

+++<div class="pagebreak"> </div>+++

[#s_Related-Documents]

== Recommended Reading/Related Documents

._Click to show the Related Documents table_
[%collapsible]
====

[#t_Related-Documents]

.Related Documents

[table.withborders,width="100%",cols="51%,49%",options="header",]
|===
|Doc. No. |Title
.^|xref:RoadViewALPR:DocList.adoc[RV-ALPRrrr-MAN-001] |{docproductname} Release Notes (for Release rrr)
.^|xref:IZIO:DocList.adoc[{hw-iocontroller}-6060-MAN-001] |{hw-iocontroller} Digital IO Controller Installation and User Guide
.^|xref:IZIO:DocList.adoc[{hw-iocontroller}-6060-TECH-002] |ADAM ({hw-iocontroller}) P2P Configuration
a|
xref:IZREMRELAY:DocList.adoc[IZREMRELAY-REV-A-TDSHEET]

xref:IZREMRELAY:DocList.adoc[Supporting Documentation]

.^|{hw-webrelay-single} Remote (Web) Relays Series: Data Sheet and supporting documentation
.^|xref:IZDiscovery:DocList.adoc[{software-discovery} Utility] |{software-discovery} Utility software components
.^|xref:IZDiscovery:DocList.adoc[IZDISCOVERY-MAN-001] |{software-discovery} User Guide
.^|xref:ZAP-4-5:DocList.adoc[ZAP-450-SDK-002] |ZAP: {compname-long} Application Protocol, Version 4.5
.^|xref:ZAP-4-5:DocList.adoc[API-HTTPM-ICD-00n_INEX_HTTP_API_Rx_y_v_W] |{compname-short} HTTP API for Major Version "M", Release "x.y"; document version W
.^|xref:IZMONSERVER:DocList.adoc[IZMSAPI-HTTP-ICD-041] |{software-monitoring}: Camera Monitoring API
.^|xref:IZMONSERVER:DocList.adoc[IZMSAPI-HTTP-ICD-042] |{software-monitoring} API
.^|xref:IZCentral:DocList.adoc[IZCENTRAL-CORE-MAN-001] |{software-server} User Guide
.^|xref:EULA:DocList.adoc[EULA-400-DOC-001] |Software End User License Agreement (includes list of open source software)
.^|xref:SLN-AmanoONE:DocList.adoc[RV-AMANO-MAN-001] |{compname-short} ALPR Installation for AMANO
.^|xref:SLN-IZCloudIntegration:DocList.adoc[RV-IZCLOUD-MAN-001] |{compname-short} {software-cloud} Integration
.^|xref:SLN-TIBA:DocList.adoc[RV-TIBA-MAN-001] |{compname-short} TIBA Integration
|===

====

+++<div class="pagebreak"> </div>+++

[#s_Applicability]

== Applicability

This document is applicable to {docproductname} software, release 1.15.64 and above.

== Training and Support

[#s_Training]

include::ROOT:partial$p-training.adoc[Training Section]

[#s_Support]

include::ROOT:partial$p-support.adoc[Support Section - With Link to INEX Website]

+++<div class="pagebreak"> </div>+++

[#s_Glossary-of-Terms]

== Glossary of Terms
._Click to show the Glossary_
[%collapsible]
====

[#t_Glossary]

.Glossary

[table.withborders,width="100%",cols="25%,75%",options="header",]
|===
|Term |Explanation
|ALPR |Automatic License Plate Recognition
|DHCP |Dynamic Host Configuration Protocol. A DHCP server assigns a unique Internet Protocol (IP) address to each device connected to a network.
|DPU |DPU is a generic term for {compname-med} Data Processing Units. {shortprodname} software can run on {compname-med} DPUs with graphic processors, or on ALPR All-in-one Camera Systems with built-in processors.
|IZ |{compname-short}/ZAMIR (former company name; now called {compname-long}, also called {compname-med})
|IZ ALPR system |An Automatic License Plate Recognition system utilizing cameras and {shortprodname} software. The IZ ALPR system can capture LPR Events, and transmit them to other systems such as {software-server}.
|{software-server} |Server software that communicates with one or more IZ ALPR systems. {software-server} provides a central repository for all LPR Events generated by the {shortprodname}(s). {software-server} can also interface with many 3^rd^ party systems via their proprietary protocols.
|LPR Event |The identified occurrence of a passing vehicle by the IZ ALPR System. An LPR Event includes metadata (location, lane identifiers, timestamp, the identified license plate number, recognition confidence, and more), plus a set of related images; typically, an Overview image, an LPR camera image and an image of the license plate. Also called a Vehicle Event or Event. An Event may include images from more than one camera in the same Lane.
|.NET |Software framework that runs primarily on Microsoft Windows. See also WCF.
|NIC |Network Interface Card
|RTSP |Real Time Streaming Protocol. A network protocol designed to control streaming media servers.
|Trigger |A command sent to an IZ ALPR system to create an LPR Event. Trigger sources can be from hardware signals, generated by software, or sent by a 3^rd^ party system via various protocols.
|WCF |Windows Communication Foundation. A Microsoft class library that is included with the .NET Framework. See also .NET.
|{software-protocol} |Zamir Application Protocol - Proprietary {compname-long} protocol for interfacing with an IZ ALPR system and {software-server}.
|===

====

[#s_System-Overview]

== System Overview

{shortprodname} is advanced ALPR software that reads license plates using sophisticated image recognition algorithms, and creates LPR Events. {shortprodname} sends LPR Event data via HTTP, the proprietary {compname-short} {software-protocol} protocol or other protocols to other systems, typically {software-server} (see the {software-server} User Guide - see <<s_Related-Documents>>). {shortprodname} can be configured and monitored using a web-based GUI.

[NOTE]

========================================

{shortprodname} can send Events to {software-server} or 3^rd^ party systems using different protocols. See <<s_Trigger-Sources-and-Trigger-Modes-Overview>>.

========================================

[#s_System-Requirements]

== System Requirements

You will need to provide a laptop computer to use for configuration. +++<u>+++If you will be using the laptop outdoors, the screen must be able to be seen in strong sunlight+++</u>+++. Required software:

* Windows 10 or above - with .NET 4.5 enabled in "Windows Features"

* Chrome or Edge browser

// [NOTE]

// ========================================

// You can add an IE Tab extension to Chrome at this link (to enable access to the Flexwatch camera configuration application): +
// https://chrome.google.com/webstore/detail/ie-tab/hehijbfgiekmjfkfjpbkbammjbdenadd

// ========================================

+++<div class="pagebreak"> </div>+++

[#s_Quick-Overview-of-Steps]

== Quick Overview of Steps

* Reserve IP addresses for the components in your ALPR system - {shortprodname} computer(s) and camera(s) - see <<s_Reserving-IP-Addresses-in-your-Network>>.

* Use {software-discovery} to find the initial IP Addresses of the cameras connected to your network - see <<s_Determining-the-IP-Addresses-of-the-Connected-Cameras>>.

* Log into each camera, and change its IP address according to the requirements of your network. +++<u>+++Use fixed addresses+++</u>+++. Record these new addresses for use in {shortprodname} configuration. See <<s_Changing-the-IP-Addresses-of-the-Cameras>>.

* Use {software-discovery} to find the IP address of the {shortprodname} computer. Change the computer's IP address according to the requirements of your network. See <<s_Determining-the-IP-Address-of-the-RoadView-Computer-with-IZ-Discovery>> and <<s_Changing-a-Device-s-IP-Address-and-Network-Settings>>.

* Review the different trigger sources and sequences, and triggering operational modes (see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>)

* Log in to {shortprodname}, and configure {shortprodname} using the Settings tab, including adding the connected Lanes and cameras - see <<s_Settings-Tab>>

* On the Calibration tab, adjust the zoom and focus to get a clear, sharp picture. Set the expected plate minimum and maximum width, capture zone and other parameters. See <<s_Calibration-Tab>>.

* On the Live tab, verify that Events are being generated for each vehicle passing each camera, and that the recognition has sufficient accuracy and confidence. See <<s_Live-Journal-Tab>>.

* Use the Search tab to find records stored in the {shortprodname} database. See <<s_Search-Tab>>.

+++<div class="pagebreak"> </div>+++

[#s_Preparation-for-Configuration]

== Preparation for Configuration

[#s_Connecting-a-Computer-Laptop-to-the-Network]

=== Connecting a Computer/Laptop to the Network

[#f_Connecting-a-Laptop]

.Connecting a Laptop

image::ROOT:RoadViewALPR/ConnectLaptopToLAN.png[image,width=312,height=195]

Connect your laptop to the same network switch the computer running {shortprodname} is connected to.

[#s_Reserving-IP-Addresses-in-your-Network]

=== Reserving IP Addresses in your Network

The {compname-short} cameras have been pre-configured with default IP addresses. You will probably need to change these addresses to conform to the requirements of your network. Be sure that you have IP addresses reserved for all components of your ALPR system ({shortprodname} computer and cameras).

[#s_Determining-the-IP-Addresses-of-the-Connected-Cameras]

=== Determining the IP Addresses of the Connected Cameras

See your camera's Installation Guide for an explanation of how to determine the initial IP addresses of cameras on your network (using {software-discovery}). You will need this information to log into the cameras, and to change the cameras' IP addresses.

[#s_Changing-the-IP-Addresses-of-the-Cameras]

=== Changing the IP Addresses of the Cameras

See your camera's Installation Guide for an explanation of how to log in to a camera, and how to edit its IP address (fixed addresses are highly recommended). Record the new addresses; you will need them to configure the {shortprodname} software.

[#s_Determining-the-IP-Address-of-the-RoadView-Computer-with-IZ-Discovery]

=== Determining the IP Address of the {shortprodname} Computer with {software-discovery}

See the {software-discovery} User Guide (see <<s_Related-Documents>>).

[#s_Changing-a-Device-s-IP-Address-and-Network-Settings]

=== Changing a Device's IP Address and Network Settings

See the {software-discovery} User Guide (see <<s_Related-Documents>>).

+++<div class="pagebreak"> </div>+++

[#s_Logging-In-and-Logging-Out]

== Logging In, Changing/Resetting Password and Logging Out

[#s_First-Time-Login]

=== First-Time Login

. Open a browser (latest version of Chrome or IE 11 or higher). Type in the IP address of the {shortprodname} computer. For example: +
{ip-default-IZA-DPU}
+
[IMPORTANT]

========================================

The {shortprodname} GUI can now be accessed using https at the start of the URL. This enables secure communications with the {shortprodname} GUI. However, due to the type of certification being used, you will see a security error message. Use the options on this warning screen to manually proceed to the {shortprodname} GUI.

========================================

. In the login screen, enter the default username and password: (root, root):
+
[#f_Logging-In-to-RoadView]

.Logging In to {shortprodname}

image::ROOT:/RoadViewALPR/RoadViewLoginWindow.png[image,width=209,height=143]

. You should see the {shortprodname} Live (Journal) tab (see <<s_Live-Journal-Tab>>). To configure {shortprodname}, switch to the Settings tab (see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>).

[#s_Changing-the-Password]

=== Changing the Password (Multi-line Menu Icon)

* Click on the multi-line menu icon at the upper right of the {shortprodname} screen

* Select "Change Password"

[#f_Change-Password-Multi-line-Menu]

.Change Password (Multi-line Menu)

image::./UserGuide/RV-1_15-FIG-021b_3_Line_ChangePW.png[image,width=80]

* Enter the new password and re-type it

[#f_Change-Password-Dialog]

.Change Password Dialog

image::./UserGuide/RV-1_15-FIG-021c_ChangePW_Popup.png[image,width=230]

=== Resetting the Password

If you forgot your password, you can reset it as follows:

. Open a browser (latest version of Chrome or IE 11 or higher). Type in the IP address of the {shortprodname} computer. For example: +
{ip-default-IZA-DPU}

. In the login screen, click on the Reset Password link
(see <<#f_Logging-In-to-RoadView>>).

. Using the dialog that appears, prepare an
email with the *Request* code, and click Cancel.
+
[#f_Password-Reset-Dialog]

image::./UserGuide/RV-1_15-FIG-021d_RequestPWReset_Popup.png[image,width=300]

. When you get a *Reset* code back from {compname-short},
repeat the previous steps to open the dialog again,
enter the Reset Code in the text box, and click Next.

. You will the dialog used for changing
a password (see <<f_Change-Password-Dialog>>)

. Enter the new password and re-type it

. Use the new password to log in to {shortprodname} again

[#s_Logging-Out-Multi-line-Menu-Icon]

=== Logging Out (Multi-line Menu Icon)

* Click on the multi-line menu icon at the upper right of the {shortprodname} screen

* Select "Logout"

[#f_Logout-Multi-line-Menu]

.Logout (Multi-line Menu)

image::./UserGuide/RV-1_15-FIG-020a_Logging_Out.png[image,width=80]

+++<div class="pagebreak"> </div>+++

[#s_Trigger-Sources-and-Trigger-Modes-Overview]

== Trigger Sources and Trigger Modes Overview

A trigger is a command sent to an IZ ALPR system to create an Event. Triggers can originate from hardware signals, from video analytics or from software/3^rd^ party system protocols.

[#f_Trigger-Sources-and-Sequence]

.Trigger Sources and Sequence

image::./UserGuide/image6.png[image,width=624,height=307]

The system constantly captures video frames and stores them in a buffer. However, the Triggering Mode determines if all, or only some of, these frames will be used for license plate recognition and Event building. Other parameters affect how many frames before (pre) and after (post) the trigger will be used:

* Protocol sections on the Settings tab (see <<s_Settings-Tab>>)

* Direct Trigger (see <<s_Direct-Trigger>>)

* {compname-short} I/O Controller (see <<s_INEX-I-O-Controller>>)

* Trigger Offset (see <<s_Trigger-Offset>>)

* The number of Trigger Pre and Trigger Post frames (defined when a camera is configured - see <<s_Cameras>>)

[NOTE]

========================================

DOT cameras take images of USDOT numbers, but do not perform LPR recognition. However, {shortprodname} will generate Events even without LPR recognition.

========================================

The Trigger Operational Modes (set in the Detector Configuration section of the Settings tab - see <<s_Detector-Configuration>>) affect how Events are created (see <<f_Trigger-Operational-Modes>>):

[#f_Trigger-Operational-Modes]

.Trigger Operational Modes

image::./UserGuide/image7.png[image,width=632,height=431]

* +++<u>+++NonTriggered+++</u>+++ - Events are created and reported using LPR video analytics

* +++<u>+++Triggered+++</u>+++ - Events are created and reported when a trigger is received
+
[NOTE]

========================================

Triggered mode must be used for DOT (USDOT number image capture) cameras.

========================================

* +++<u>+++Hybrid+++</u>+++ - Events are continually created internally by LPR video analytics, but are only reported when a trigger is received. The Event closest in time to the trigger will be reported (sent to storage). See <<s_Detector-Configuration>> where the Hybrid Pre/Post Time parameters are described.
+
[NOTE]

========================================

In Hybrid mode, if no recognition was possible (no vehicle, no plate, unrecognizable plate, etc.), an Event will be created as it would be in Triggered mode. The Event will be created using frames captured at the time the Trigger was received, along with the Trigger Pre and Post frames, instead of using the frames from the NonTriggered video analytics. +
See <<s_Trigger-Sources-and-Trigger-Modes-Overview>> and <<s_Cameras>>.

========================================

<<<

* +++<u>+++NonTriggered With Trigger+++</u>+++ - NonTriggered Events are continually created and reported by LPR video analytics. In addition, Triggered Events are created and reported when a trigger is received.

Each type of Trigger Operational Mode has its own advantages:

* *Triggered types* require external triggering hardware or software, and are more accurate. All vehicle images are recorded, even if the plate was not recognized. In addition, LPR Events can be generated on demand by third-party systems.

* *NonTriggered types* do not require any external triggering hardware (such as inductive loops). However, they are less accurate.

<<<

[#s_Settings-Tab]

== Settings Tab

Use the Settings tab after the first installation or reinstallation of the IZ ALPR system, or when some fundamental parameters need updating. For example, if the Camera System or DPU was moved to a different location (time zone).

[#f_Settings-Tab]

.Settings Tab

image::./UserGuide/RV-1_15-FIG-003f_SettingsTab.png[image,width=265,height=504]

[NOTE]

========================================

After clicking the Save button at the end of the Detector Configuration section, it will take several seconds before the Live tab can start displaying Events. Also, some defaults and/or available parameters may change, depending on the Detector Configuration "Mode" selected.

========================================

+++<div class="pagebreak"> </div>+++

[#s_Software-Version-and-Camera-Information]

=== Software Version and Camera Information

The box at the upper right of the Settings screen shows:

* The {shortprodname} software version

* The model, part number and serial number of the camera(s) {shortprodname} is communicating with:

[#f_Software-Version-and-Camera-Information-Section]

.Software Version and Camera Information Section

//remember to update this image file with the
//latest version when the software is released
//to production

image::./UserGuide/RV-1_15-FIG-100b_SettingsVersionSection.png[image,width=356,height=130]

[#s_Network-Settings]

=== Network Settings

[#f_Network-Settings-Section]

.Network Settings Section

image::ROOT:RoadViewALPR/RV-1_15-FIG-213_NewNetworkSettings.png[image,width=416,height=180]

* If needed, set the {shortprodname} computer's IP address parameters.

* The IP Address and Default Gateway must be on the same network.

* Remember to click the Save button in this section; the change will be applied immediately.

[IMPORTANT]

========================================

The Network Settings refer to the +++<u>+++{shortprodname} computer+++</u>+++ (+++<u>+++Camera System or DPU)+++</u>+++ - NOT the computer on which the browser displaying the GUI is running.

*+++<u>+++It is highly recommended to use a fixed IP address (not DHCP)+++</u>+++*. A fixed IP address enables you to access the computer using the same URL every time, even after unexpected power outages.

========================================

+++<div class="pagebreak"> </div>+++

[#s_FTP-SFTP-Settings]

=== FTP/SFTP Settings

[#f_FTP-SFTP-Section]

.FTP/SFTP Section

image::./UserGuide/image11.png[image,width=468,height=204]

* Select the desired communication protocol - FTP, SFTP, or both +
Be sure to click the Save button at the end of this section if you change these protocol selections, or if you enable or disable FTP or SFTP (check boxes).

* Separate sections will appear for FTP and SFTP, enabling you to click a button to add user(s) who can connect to a {shortprodname} computer via FTP/SFTP

** FTP users are automatically added as SFTP users

** Deleting an SFTP user will automatically delete the user from FTP

** The Port is fixed; this is the port that the users' system will use to communicate with the {shortprodname} computer
+
[#f_Adding-an-SFTP-User]

.Adding an SFTP User

image::./UserGuide/image12.png[image,width=176,height=129]

* Each user that appears in the table can be edited or deleted; however, only the password can be edited. In order to rename a user, you will need to delete the existing user and re-enter it.

* Remember to click Save after changing the password.

* If a user is added, deleted or changed (except for a password change), the changes are saved automatically

+++<div class="pagebreak"> </div>+++

[#s_Date-and-Time-Settings]

=== Date and Time Settings

[IMPORTANT]

========================================

The Date and Time Settings refer to the location of the +++<u>+++{shortprodname} computer+++</u>+++ (+++<u>+++Camera System or DPU)+++</u>+++ - NOT the computer on which the browser displaying the GUI is running.

The Time Zone selections are organized by continent. For example, the "America/" prefix covers various cities and countries in North America (U.S. and Canada) and South America.

========================================

[#f_Date-and-Time-Settings-Section]

.Date and Time Settings Section

image::./UserGuide/image13.png[image,width=490,height=180]

* Set Time (Automatically/Manually)

** If *Automatic*, the date and time will be updated from a central Network Time server. Select the appropriate server, and the interval at which you want {shortprodname} to poll for the date and time (selected from the Polling Interval dropdown).

*** Click the "Update Now" button to update the date and time immediately.

*** The icon (green check mark or red "x") indicates if the URL of the NTP server is correct, and the connection to it was successful.

** If *Manual*, click in the *Date and Time* box to display a calendar/time popup. You should also select a *Time Zone*; set it to the local time at the location in which the Camera System/DPU is installed (+++<u>+++not+++</u>+++ the UTC default).

* Remember to click the Save button at the end of this section after making changes.

+++<div class="pagebreak"> </div>+++

[#s_HTTP-Integration]

=== HTTP Integration

[#f_HTTP-Integration-Section]

.HTTP Integration Section

image::./UserGuide/image14.png[image,width=698,height=49]

[NOTE]

========================================

{shortprodname} can send Events to {software-server} or 3^rd^ party systems using the {compname-short} HTTP Protocol, {compname-short} {software-protocol} Protocol or other protocols. For details about the {compname-short} HTTP protocol, see the appropriate {compname-short} HTTP API Protocol document - see <<s_Related-Documents>>.

{shortprodname} can send Events via HTTP, and act as both a {software-protocol} Server and {software-protocol} Client - all simultaneously.

If you are using an IZMobileLPI system, contact {compname-short} for details on how to set the HTTP URL parameter.

========================================

* Click Add HTTP Integration. Note that this feature enables you to use multiple HTTP channels (see <<f_Adding-an-HTTP-Integration>>).

[#f_Adding-an-HTTP-Integration]

.Adding an HTTP Integration

image::./UserGuide/RV-1_15-FIG-020b_Edit_HTTP_Integration.png[image,width=300]

<<<

* *HTTP URL* - URL for an external system to listen on, in order to receive Events from {shortprodname} via the {compname-short} HTTP protocol (see the appropriate {compname-short} HTTP API Protocol document - see <<s_Related-Documents>>).
+
[NOTE]

========================================

For an external system, "api" at the end of the URL is optional.

For {software-server}, "api" is mandatory; also, {software-server} currently only works with HTTP API 1.3 (chosen from the Protocol Version dropdown).

========================================

** Be sure to use the correct format: +
\http://<IP address of {software-server} or 3^rd^ party computer>:<port number>/api +
For example (port is typically 5801): +
\http://195.163.2.73:5801/api
+
[IMPORTANT]

========================================

For secure communication, https can be used in the URL. In such a case, use the port registered for secure communication in {software-server} (for example, 11443). However, {software-server} must be configured to accept an encrypted connection (see the {software-server} User Guide for details - see <<s_Related-Documents>>).

========================================

* *Protocol Version* - The appropriate HTTP API version to use for your application.
+
[NOTE]

========================================

In {compname-short} HTTP API version 1.5, the following items have not been implemented in {shortprodname}: +
camera_id and camera_name in the Upload Event command (images and lpr_results blocks) +
See the HTTP API 1.5 document.

========================================

* *Separated Images* - If checked, then images are sent in separate messages after the Event message; if unchecked, images and the Event are sent together in the Event message.

* *Send Images Data* (automatically checked for HTTP API 2.3 and above, as chosen from the Protocol Version dropdown) - If checked, then image data is sent as "data base64 encoded" inside the message; if unchecked, this field is not included in the message.

* *Offline Enabled -* Used if you want to enable offline saving of Events and images via HTTP. If you try to send an Event, but do not have a connection to the server, then this event will be put in an offline queue, and sent again when connection with the server is restored. Note that if you enable offline capabilities, you must configure the offline queue parameters (see <<s_Offline-Queue>>).

* *Send Triggers* (only enabled for HTTP API
versions 1.3 to 1.6, as chosen from the
Protocol Version dropdown) - If checked,
then {shortprodname} will send Trigger
Received messages to the server.
The meaning of this command is:
The camera has received a trigger
to create an Event.
The Event is being processed,
and will be available soon.

* *Send NT Triggers* (for protocols 1.x only) -
If enabled, if {shortprodname} receives a
Non-triggered Event, then {shortprodname} will
send a "Trigger Received" HTTP API message to
the client.

* *Keep Alive Interval* (ms) - How often a status message is sent from {shortprodname} to the server

* *Event/Images Timeout* (ms) - If an Event or image message cannot be sent for this timeout period, then the event/image is put in the offline queue

* *Trigger Enabled* - When an Event is received,
send a trigger with recognition data to another
{shortprodname}; the second {shortprodname}
will create a new Event with the received recognition data.

* *Trigger Lane ID* - The
Lane ID to which triggers will be sent when the
Trigger Enabled parameter is enabled.

* *Status Enabled* - When checked, {shortprodname}
will send HTTP API status messages to the client.

* *Status Timeout* (ms) - If an HTTP API status message
cannot be sent to the server for this amount
of time, {shortprodname} stops sending
the message, and sends it again at the next
Keep Alive Interval.

* *Lane ID* - The Lane from which Events and statuses will be sent ("All" or a specific Lane)

* After clicking the Save button, adding/editing an integration can take several seconds

* Each integration (channel) that appears in the table can be edited or deleted

* If you delete an entry, you will be asked to verify the deletion.

[#s_Passageway-Combination]

=== Passageway Combination

image::./UserGuide/RV-1_15-FIG-204_Passageway_Combination.png[image,width=300]

This feature is typically used when entry and exit cameras have
a direct integration with a 3^rd^ party system.

[IMPORTANT]
==============================
This feature can only be enabled on the
+++<u>+++exit+++</u>+++ camera
(see <<f_Add-Edit-Lane-Dialog>> in <<s_Lanes>>).
==============================

The LPR entry read is sent to a server connected
via our standard HTTP API (usually a 3^rd^ party server).

Upon exit, the LPR exit read is compared with all
reads stored in the server that have
not yet exited. If the match is close enough, then the camera
reports the LPR +++<u>+++entry+++</u>+++ read via HTTP API to
the 3^rd^ party's integration system. This enables the 3^rd^ party
system to create more accurate entry/exit transactions.

* Remember to click the Save button at the end of the
Detector Configuration section after making changes.

<<<

[#s_Plate-Recognizer-Not-Used]

=== Plate Recognizer (Not Used)

Not used; do not enable

[#s_IZCloud-Integration]

=== {software-cloud} Integration

See the {software-cloud} document (see <<s_Related-Documents>>).

[#s_Raytec-LED-Illuminators]

=== {illum-3rd-party} LED Illuminators

[#f_Raytec-LED-Illuminators-Section]

.{illum-3rd-party} LED Illuminators

image::./UserGuide/RV-1_15-FIG-207_Raytec_LEDs.png[image,800]

[NOTE]
========================
If {illum-3rd-party} LED Illuminators are enabled, their
statuses will appear on the System Status tab (see <<s_System-Status-Tab>>).
========================
* *URL* - Illuminator's URL

* *Username, Password* - Illuminator's username and
password; see the manufacturer's documentation
or ask your system administrator for these
credentials.

* *Level* - The percentage of LED power to
be used; acceptable range is 20-100

* *Delay On/Off* (ms) - The amount of time for
{shortprodname} to wait after receiving a
signal from an {compname-short} I/O Controller ({hw-iocontroller})
before turning the illuminator
ON or OFF (see <<s_INEX-I-O-Controller>>).
Controller signal output can be configured
to turn the illuminator ON or OFF, according to
the signal received from the controller; see the
Signal parameter in this section.

* *IP* - IP address of the controller

* *Input* - The number of the controller output that {shortprodname}
is polling.

* *Signal* - The output signal level of the controller
defined to turn the illuminator ON.

** +++<u>+++Disabled+++</u>+++ - {shortprodname} does not use the signal to affect
the illuminator

** +++<u>+++High+++</u>+++ - A high output turns the illuminator ON

** +++<u>+++Low+++</u>+++ - A low output turns the illuminator ON

* Click the Add button to add the illuminator to the list

* Click the Delete button to remove the illuminator from the list

* Remember to click the Save button at the end of the
Detector Configuration section after making changes.

<<<

[#s_AMANO-Integration]

=== AMANO Integration

See the AMANO document (see <<s_Related-Documents>>).

[#s_TIBA-Integration]

=== TIBA Integration

See the TIBA document (see <<s_Related-Documents>>).

[#s_Designa-Integration]

=== Designa Integration

See separate document.

[#s_Offline-Queue]

=== Offline Queue

[#f_Offline-Queue-Section]

.Offline Queue Section

image::./UserGuide/image16.png[image,width=528,height=158]

These parameters are currently used to configure offline Event storage for HTTP Integration (see <<s_HTTP-Integration>>)

* *Send Offline Events Every* - not currently used

* *Expiration Enabled* - Enables the following parameters:

** *Offline Events Expire After* - If an Event was added to the offline queue because there was no connection with client, and the connection with the client was not restored within this time, the Event will be removed from the offline queue.

** *Send Offline Events After* - not currently used

+++<div class="pagebreak"> </div>+++

[#s_Monitoring-IZMonitoring-Server-Integration]

=== Monitoring ({software-monitoring} Integration)

[#f_Monitoring-Section]

.Monitoring Section

image::./UserGuide/image17.png[image,width=493,height=152]

When Monitoring Integration ({software-monitoring} Integration) is enabled, the following parameters appear:

* *URL* - URL of the {software-monitoring}

* *Keep Alive Timeout (seconds)* - How often {shortprodname} sends Keep Alive messages. If the Server does not receive another Keep Alive message before this time expires, the overall status (severity) of the product (camera) will be set to "Offline" automatically by the Server.

* *Status Timeout (seconds)* - How often {shortprodname} sends a full status message to the Server.

* *Disk Critical Threshold -* When the percentage of used space on the disk (where the {shortprodname} storage is located) is above this number, then a critical disk status is sent to the Server.

* Remember to click the Save button at the end of the Detector Configuration section after making changes.

+++<div class="pagebreak"> </div>+++

[#s_ZAP-Integration]

=== {software-protocol} Integration

//*_\{Zvulun: check capitalization of start of all bullets - cap or no cap}_*

[#f_ZAP-Integration-Section]

.{software-protocol} Integration Section

image::./UserGuide/RV-1_15-FIG-206_ZAP_Integration.png[image,width=393]

[NOTE]

========================================

{shortprodname} can send Events to {software-server} or 3^rd^ party systems using the {compname-short} HTTP Protocol (see <<s_HTTP-Integration>>) and/or the {compname-short} {software-protocol} Protocol.

{shortprodname} can send Events via HTTP, and act as both a {software-protocol} Server and {software-protocol} Client - all simultaneously.

Remember to click the Save button under the Detection Configuration section after changing these parameters.

========================================

* *{software-protocol} Server* - Check the box to have {shortprodname} act as a {software-protocol} Server, to which {software-protocol} Clients can connect (see the {software-protocol} Protocol document for details):

** *Ports* - Each Lane configured in {shortprodname}
will automatically have its own row in the table.

*** +++<u>+++Port+++</u>+++ - Each Lane should have
a different port number. This field is automatically
populated when a new Lane is added (see <<s_Lanes>>), but can be edited.
These are the TCP ports that {shortprodname} is listening
on for connection from a 3^rd^ party application.

*** +++<u>+++Report As+++</u>+++ - How a {software-protocol}
disconnection is reported (via the {software-protocol}
protocol) in the {software-protocol}
status message (Information, Warning or Critical)

*** +++<u>+++Enable Auto Self-Triggering+++</u>+++ -
(Requires Offline to be Enabled in the ZAP section)
+
If enabled, {shortprodname} will switch to
Non-triggered mode if a GetStatus message not received
from the {software-protocol} client or server.
This enables some record/images of the Event to be saved
even though triggers can't be sent.
After {shortprodname} re-connects to {software-protocol},
{shortprodname} attempts to send all Events that were
created offline back to {software-protocol}.

*** +++<u>+++Auto Self-Triggering Timeout+++</u>+++ -
How long (in ms) to wait (after the GetStatus message was
not received from the {software-protocol} client or server before switching to
Self-Triggering mode

** *{software-protocol} Version* - {software-protocol}
communication protocol version. It is recommended to use
the latest version. The connected clients must use the same version.

** *Confidence Filter* - The confidence level below which Events are not sent

** *Keep Time (seconds)* - How long a Capture message is to be left in memory before it will be deleted (if a Keep message is not received)

** *Send One LP* - If LPR results are found from multiple images
of the same Event, {shortprodname} will only send one of them via the {software-protocol} protocol.

** *Images Selection* - see <<s_ZAP-Images-Selection>>

** *Offline Enabled* - Check this box to enable the {software-protocol} offline queue

** *FTP Enabled (for {software-protocol} Server)* - When a client is connected to {shortprodname} via {software-protocol}, images can be sent to the client via FTP if this checkbox is checked.

*** +++<u>+++FTP Server+++</u>+++ - The IP address of the FTP server

*** +++<u>+++FTP Port+++</u>+++ - The port on the FTP server listening for FTP messages

*** +++<u>+++FTP Folder+++</u>+++ - The folder path on the FTP server where the images will be stored

*** +++<u>+++FTP User+++</u>+++ - The username used to access the FTP server

*** +++<u>+++FTP Password+++</u>+++ - The password used to access the FTP server

*** +++<u>+++FTP Keep Alive Rate (seconds)+++</u>+++ - The time (in seconds) between attempts to check that the connection with the FTP server is still alive

* *{software-protocol} Client* - Check the box to have {shortprodname} act as a {software-protocol} Client, which will connect to a {software-protocol} Server (see the {software-protocol} Protocol document for details). +
 +
If you want {shortprodname} to work with {software-server}, {shortprodname} can only be working as a {software-protocol} Client. In this mode, the {shortprodname} {software-protocol} Client port must match the {software-server} {software-protocol} port (see the {software-server} documentation - see <<s_Related-Documents>>)

** *IP* - The IP address of the {software-protocol} Server (to which {shortprodname} acting as a client should connect)

** *Port* - The TCP port number of the 3^rd^ party application to which
{shortprodname} will connect.

** *{software-protocol} Version* - {software-protocol} communication protocol
version. It is recommended to use the latest version. The 3^rd^ party
application being connected to must use the same version.

** *Confidence Filter* - The confidence level below which Events are not
sent

** *Keep Time (seconds)* - How long a Capture message is to be left in memory before it will be deleted (if a Keep message is not received)

** *Offline Enabled* - Check this box to enable the {software-protocol} offline queue

** *FTP Enabled (for {software-protocol} Client)* - When {shortprodname} is connected to a {software-protocol} server, images can be sent to the server via FTP if this checkbox is checked. (See the FTP Server items for the definition of the additional FTP parameters.)

[#s_ZAP-Images-Selection]

=== {software-protocol} Integration - Images Selection

When an Event is generated in
triggered or non-triggered modes, the system
sends a set of images for that Event.

The system can generate two types of Events:

* In which a license plate was found (License Plate Found)

* In which a license plate was not found in the images taken (License Plate Not Found)

Each image has the following properties:

* Image type defined by the sensor - LPR or OV

* Image post-processing - Full, Cropped (cropped from
full image) or ROI (region of interest - only the
licesnse plate cutout)

* ALPR/State confidence level - 0 if there is no
license plate found in the image, or N a number
from 1-99

* Set of coordinates in the full image where a
license plate was found - 0 if there is no
license plate found, or the x1y1, x2y2 coordinates
of the license plate

==== License Plate Found

* *LPR Only* - (Case 1) A full LPR image where plate is visible, selected
from a range of the highest recognition confidence levels, in which
the license plate coordinates are closest to the bottom of the frame. +
(Case 2) If there is no LPR image with a visible license plate,
but there is an OV image with a license plate,
send one OV image using the same rules as for the LPR image in
case 1 for this mode.

* *1 LPR and 1 LPR ROI* - A full LPR image where plate is visible,
selected from a range of the highest recognition confidence levels,
in which the license plate coordinates are closest to the bottom of
the frame - plus a license plate patch image from an LPR frame with
the highest confidence level. +
{empty} +
If there is no LPR image with a visible license plate,
but there is an OV image with a license plate, send
a full OV image where the plate is visible,
selected from a range of the highest recognition confidence levels,
in which the license plate coordinates are closest to the bottom of
the frame - plus a license plate patch image from an OV frame with
the highest confidence level.

* *OV Only* - (Case 1) A full OV image where plate is visible, selected
from a range of the highest recognition confidence levels, in which
the license plate coordinates are closest to the bottom of the frame. +
(Case 2) If there is no OV image with a visible license plate,
but there is an LPR image with a license plate,
send one LPR image using the same rules as for the OV image in case
1 for this mode.

* *1 OV and 1 OV ROI* - A full OV image where plate is visible,
selected from a range of the highest recognition confidence levels,
in which the license plate coordinates are closest to the bottom of
the frame - plus a license plate patch image from an OV frame with
the highest confidence level. +
{empty} +
If there is no OV image with a visible license plate,
but there is an LPR image with a license plate, send
a full LPR image where the plate is visible,
selected from a range of the highest recognition confidence levels,
in which the license plate coordinates are closest to the bottom of
the frame - plus a license plate patch image from an LPR frame with
the highest confidence level.

* *1 Cropped OV and 1 OV ROI* - Same as both cases "1 OV and 1 OV ROI", but
the overall image will be cropped according to the Crop Width and Crop
height parameters which appear. The license plate will appear in
the center of the cropped image.

** If the Crop Height is zero, then the width of cropped image will be
fixed, and the height of the cropped image will be the
same as the proportion of the Crop Width to the original frame. +
For example, if the original frame's size is 1600 x 900 pixels,
and the Crop Height is 0 and the Crop Width is 800 (half of the original),
then the height of the cropped images will be 450 (half of the original) +

** If the Crop Width is zero, then the height of cropped image will be
fixed, and the width of the cropped image will be the
same as the proportion of the Crop Height to the original frame.

* *1 OV, 1 OV ROI, 1 LPR, 1 LPR ROI* - Same as
case 1 of "1 OV and 1 OV ROI", together with case 1 of "1 LPR and 1 LPR ROI"

** If there is no LPR image with a visible license plate,
LPR images are not sent.

** If there is no OV image with a visible license plate,
OV images are not sent.

* *All OV, all OV ROI, all LPR, all LPR ROI* -
Send all LPR and OV images, even if there was no plate recognition

==== License Plate Not Found

* *LPR Only* - Send one LPR image with a
timestamp closest to the trigger timestamp

* *1 LPR and 1 LPR ROI* - Send one LPR image with a
timestamp closest to the trigger timestamp

* *OV Only* - Send one OV image with a
timestamp closest to the trigger timestamp

* *1 OV and 1 OV ROI* - Send one OV image with a
timestamp closest to the trigger timestamp

* *1 OV, 1 OV ROI, 1 LPR, 1 LPR ROI* - Images are not sent

* *All OV, all OV ROI, all LPR, all LPR ROI* - Send all LPR and all OV images

<<<

[#s_Direct-Trigger]

=== Direct Trigger

[#f_Direct-Trigger-Section]

.Direct Trigger Section

image::./UserGuide/image19.png[image,width=287,height=43]

The Direct Trigger settings are used in these operational modes: Triggered, Hybrid or NonTriggered With Trigger (see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>).

This parameter is used for Camera System models with external trigger input wires, such as the IZA500G. See your Camera System's Installation Guide for details.

A loop controller can provide trigger information to {shortprodname}. You can connect dry or wet contacts to the Camera System's trigger inputs. The rise and fall of the voltage levels at these inputs sends a trigger to {shortprodname} (see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>).

The "trigger time" used can be influenced by using the rising edge or falling edge of the pulse at the inputs to the Camera System. The Direct trigger mode options are (see <<f_Trigger-Sources-and-Sequence>>):

* +++<u>+++Disabled+++</u>+++ - Triggers will not be generated

* +++<u>+++OnRise+++</u>+++ - A trigger is generated when the voltage level sensed on the trigger wires moves from low to high

* +++<u>+++OnFall+++</u>+++ - A trigger is generated when the voltage level sensed on the trigger wires moves from high to low

* Remember to click the Save button under the Detection Configuration section after changing these parameters.

<<<

[#s_INEX-I-O-Controller]

=== {compname-short} I/O Controller

[#f_INEX-I-O-Controller-Section]

.{compname-short} I/O Controller Section

image::./UserGuide/image20.png[image,width=363,height=107]

The {compname-short} I/O Controller settings are used in Triggered types of operational modes (for example Triggered, Hybrid or NonTriggered With Trigger). See <<s_Trigger-Sources-and-Trigger-Modes-Overview>>.

These parameters are used if triggers are sent via the LAN using an {compname-short} {hw-iocontroller} Digital I/O Controller. See the {hw-iocontroller} Installation and User Guide for instructions on how to install and configure the {hw-iocontroller} (especially its IP address). See <<s_Related-Documents>>.

The {hw-iocontroller} provides trigger information to {shortprodname}. You can connect dry or wet contacts to the {hw-iocontroller} inputs. The rise and fall of the voltage levels at these inputs (such as pulses from loop controllers) are represented by a bit stream sent by the {hw-iocontroller}/ADAM to {shortprodname}. A change in state of an {hw-iocontroller} input causes the generation of a trigger (see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>).

In Server mode, advanced P2P mode support was added (available via the {hw-iocontroller}/ADAM configuration application); this enables the {hw-iocontroller}/ADAM to send state changes to multiple {shortprodname} instances. See the P2P document (see <<s_Related-Documents>>).

* *Pulling or Server -* how the digitized pulses are obtained by {shortprodname}

** +++<u>+++Pulling+++</u>+++ - {shortprodname} will request state changes from the {hw-iocontroller}, sampled every 20 ms

** +++<u>+++Server+++</u>+++ - {hw-iocontroller} sends a notification of a state change to {shortprodname} (sampling is not needed)

* *Lane ID* - The Lane ID as defined in the lower part of the Settings tab

* *IP Address* - {hw-iocontroller}'s IP address (configured via the {hw-iocontroller} configuration software. See the {hw-iocontroller} Guide for details (see <<s_Related-Documents>>).

* *Input* - The input channel on the {hw-iocontroller} to be polled/sampled

* *Trigger mode* - The "trigger time" used can be influenced by using the rising edge or falling edge of the pulse at the IO input of the {hw-iocontroller}/ADAM. The options are (see <<f_Trigger-Sources-and-Sequence>>):

** +++<u>+++Disabled+++</u>+++ - Triggers will not be generated

** +++<u>+++OnRise+++</u>+++ - A trigger is generated when the voltage level sensed on the trigger wires moves from low to high

** +++<u>+++OnFall+++</u>+++ - A trigger is generated when the voltage level sensed on the trigger wires moves from high to low

* Remember to click the Save button under the Detection Configuration section after changing these parameters.

//[#s_ICP-Integration-Not-Currently-Used]

//=== ICP Integration (Not Currently Used)

//See separate document.

//[#s_IRD-Integration-Not-Currently-Used]

//=== IRD Integration (Not Currently Used)

//See separate document.

+++<div class="pagebreak"> </div>+++

[#s_Journal-Optional-Local-Storage]

=== Journal (Optional Local Storage)

[#f_Journal-Section]

.Journal Section

image::./UserGuide/image21.png[image,width=458,height=129]

The Journal (Local Storage) parameters determine if and how Events are stored on the local {shortprodname} computer disk (the parameters only appear if the disk is in use).

The Journal data is stored at: /mnt/data/journal

* *Cleanup Interval* - Interval in milliseconds at which old Events are deleted in order to be within Max Count on Disk

* *Max Count on Disk* - Maximum number of Events that can be stored
on the {shortprodname} computer's disk; this parameter should be left at its default

[NOTE]

====================
If needed, the Max Count on Disk can currently support up to 100,000 events

If there is not enough free disk space to accommodate the
Max Count on Disk number of Events, the system will delete
old Events and store new Events only.

====================

[#s_Events-Post-Processing]

=== Events Post Processing

[#s_Events-Post-Processing-Section-Skip-Empty-Events]

==== Skip Empty Events

* *Skip Empty Events* - (see <<f_Events-Post-Processing-Section-Combine-Enabled>>) When an Event does not include a plate recognition,
it is ignored.

[#s_Events-Post-Processing-Section-Combine-Enabled]

==== Combine Enabled

[#f_Events-Post-Processing-Section-Combine-Enabled]

.Events Post-Processing Section - Combine Enabled

image::./UserGuide/RV-1_15-FIG-208_Events_Post_Combine.png[image,width=480,height=160]

* *Combine Enabled* - used for combining Events with the same or similar recognition

** *Combine Send Timeout* - If another Event is received with the same or similar recognition results within this timeout, the two Events are merged into one Event

** *Combine Lev Distance* - The maximum Levenshtein distance between
the two plate reads for which the Events will be combined
(see <<s_Detector-Configuration>> for a more detailed explanation
of Levenshtein distance).

** *Align to Height* - When the LPR and OV images from the Events are
merged, {shortprodname} selects the images in which the plate patch
is closest to this percentage of the total height of the LPR/OV
image. For example, if the images are 1000 pixels high, and this
parameter is set to 75%, then {shortprodname} selects images in
which the plate patch is closest (either above or below) a
virtual line 750 pixels from the top of the image.


[#s_Events-Post-Processing-Section-SkipByDistance-Enabled]

==== Skip By Distance Enabled

[#f_Events-Post-Processing-Section-SkipByDistance-Enabled]

.Events Post-Processing Section - Skip By Distance Enabled

image::./UserGuide/RV-1_15-FIG-209_Events_Post_Skip.png[image,width=480,height=160]

* *Skip By Distance Enabled* - used for skipping Events

** *Hold Timeout* - How much time between two Events with similar plate reads
for the skip to occur. This timeout is renewed after the skip.

** *Skip Lev Distance* - If the Levenshtein difference between
similar LPR reads from the same lane is less than or equal to the Skip Lev Distance,
then the new Event will be skipped. (See <<s_Detector-Configuration>> for a more detailed explanation
of Levenshtein distance.)

[#s_Trigger-Offset]

=== Trigger Offset

[#f_Trigger-Offset-Section]

.Trigger Offset Section

image::./UserGuide/image23.png[image,width=477,height=85]

The Trigger Offset affects all triggers (in all modes - see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>).

When Trigger Offset is enabled, the following parameter(s) appear:

* *Offset* (in milliseconds) - See <<s_Trigger-Sources-and-Trigger-Modes-Overview>>

The trigger command may arrive at a different time than actual trigger's (physical) arrival time (see <<f_Trigger-Sources-and-Sequence>>). For example, there is often a delay between the time a vehicle passes over an inductive loop, and the time the loop controller generates a pulse. This latency can be compensated for by an "offset".

<<<

[#s_Detector-Configuration]

=== Detector Configuration

[#f_Detector-Configuration-Section]

.Detector Configuration Section

image::./UserGuide/RV-1_15-FIG-212_NewDetectorConfig.png[image,width=433,height=472]

Plate recognition is done in 3 stages:

* The position of the license plate is determined in each incoming frame (from each camera)

* Characters from each license plate image are read and recognized

* All of the reads of each plate are grouped to create LPR Events

The following parameters are used to configure these processes. *Remember to click the Save button at the end of this section after changing these parameters:*

* *Mode* - see <<s_Trigger-Sources-and-Trigger-Modes-Overview>>. Note that parameters may appear or be hidden, depending on the chosen Mode.

* *Region* - Region for which characters on the plate will be recognized. Select from the following options:

** +++<u>+++Australia+++</u>+++

** +++<u>+++Canada/North America+++</u>+++ - Same as North America LPR, with a different state recognition model that includes Canadian states.

** +++<u>+++Europe+++</u>+++

** +++<u>+++Israel+++</u>+++

** +++<u>+++North America+++</u>+++ - General recognition that includes all U.S.A. states

** +++<u>+++North America (OR)+++</u>+++ - Same as North America, with the addition of syntax checking (against predefined patterns of characters) for Oregon state

* *State* - The State within the selected Region for which characters on the plate will be recognized. You can also select "ALL"; this indicates that the recognition engine will use a general model for this Region.

* *Skip stacked characters (only for Regions with stacked character plates)* - When enabled, causes stacked characters to be excluded from the plate read.

* *Detector confidence threshold* - The minimum Detector confidence that this rectangle is a license plate. If a read is at or above this threshold, the image is sent on for plate reading (plate character) processing.

* *Plate reader confidence threshold* - The minimum Plate Reader confidence that the characters read are correct. If a read is at or above this threshold, an Event is created. If more than one camera is capturing images from a lane, the image with the highest confidence among the cameras is used.

* *Plate reader regexp filter* - Only license plate reads meeting these regular expression filter criteria will have Events created for them. Typically, the default should be used (.* = allow all reads).

* *Min plate read count* - To increase read accuracy, plates are read from more than one video frame. If the same plate read results match on at least this number of frames, then the Event will be created. +
For slow-moving traffic, this parameter should be increased. +
For faster traffic, you will only be able to set it to a small number of reads.

* *Wait before event emit, ms* - (affects results in NonTriggered or Hybrid modes) +
The minimum time from the first plate read until the time the Event will be built (emitted) - which can result in a greater number of frames used than the "Min plate read count" parameter. You may want to get LPR results with better confidence by increasing this number. {shortprodname} will wait for more correct reads before the Event is built (see <<f_Illustration-of-Wait-Before-Event-Emit>>). +
As a vehicle approaches a camera, waiting longer will usually (depending on road geometry) result in images of the plate getting larger and easier to read accurately. +
Note that in hybrid mode, it is recommended to set this parameter greater than 0. Setting this parameter to 0 will result in lower read confidence, since the trigger and the first read will occur close together.
+
[#f_Illustration-of-Wait-Before-Event-Emit]

.Illustration of Wait Before Event Emit

image::./UserGuide/image25.png[image,width=504,height=186]

* *LP forget interval, ms* - {shortprodname} may not have been able to read a plate over the course of several frames, which appear between two groups of frames with correct reads. +
If the size of this "hole" is large, then the vehicle has probably disappeared but then returned. This value controls whether or not to consider the two sequences of captures to be a single Event, or two separate Events.
+
[#f_Illustration-of-LP-Forget-Interval]

.Illustration of LP Forget Interval

image::./UserGuide/image26.png[image,width=507,height=97]

* *Max Levenshtein distance* - Different reads of the same plate may not be identical due to shadows, sunlight, blurred images, etc. However, we want to minimize these effects by treating slightly different reads as the same result. We allow a maximum "distance" (number of changes required to match two strings) between plate reads in an Event. If the distance is less than or equal to this parameter, then the comparison is considered to be a valid match for the Event.

* *LPR JPEG quality, 0-100 (0=no frame sent)* - The quality level used
to send and store LPR images after recognition is performed

* *OV JPEG quality, 0-100 (0=no frame sent)* - The quality level used
to send and store OV images after recognition is performed

* *Plate JPEG quality, 0-100 (0=no frame sent)* - The quality level used
to send and store plate patch images after recognition is performed

* *Include all images (for "Triggered" and "NonTriggered With Trigger" modes only)* - Enables display in Live tab, and sending of +++<u>+++all+++</u>+++ images (including pre- and post-trigger frames) - not only the "best" ones that were used for plate recognition

* *Include all LPR results* - include all plate reads in the Event (not
just the ones with the best confidence)

* *Image Resize* - When enabled, and the Event confidence is equal or higher than the Resize Confidence parameter, then each LPR and OV image is resized according to the Image Width (and the height is resized proportionally).

** *Image Width* - The resize width

** *Resize Confidence* - The Event confidence threshold for enabling resizing

* *Two Line Plate -* When enabled, invokes the capability to recognize two-line plates (in which the license plate number consists of two rows).

** *Threshold* - If the ratio of the width of the plate to its height is less than this threshold, then the plate very likely has two lines. The plate read will be the lower number added to the upper number.

** *Padding Width* (%) - The percentage of the width of the plate to be removed from each side of the upper and lower images before putting the two numbers together. This eliminates empty space before the composite number is sent for recognition.

** *Padding Height* (%) - The percentage of the height of the plate

*** This percentage is measured from the top, to determine where to crop the plate to determine how to extract the upper number's image

*** This same percentage is measured from the bottom, to determine where to crop the plate to determine how to extract the lower number's image

* *Vehicle Class Detection* - Enables/disables vehicle class detection (car, bus, etc.). This item can be shown on the Live tab using the multi-line menu at the upper right of the screen (see <<s_Live-Journal-Tab>>).

* *State recognition* - Enables state recognition (an Overview camera must have been defined and configured)

* *Send default state* *(only if State recognition* *is enabled) -* If no State was recognized, checking this box enables sending the Default State Value in the HTTP message for the Event as per the following additional parameters that appear: (If unchecked, no State field will be sent in the message.)

** *Default state value* - The default value to be sent in the HTTP message for the Event if no State was recognized.

** *State confidence threshold* - The minimum confidence percentage for State recognition

* *LPR Stub Enabled* - If a plate was detected, but without a plate read, {shortprodname} sends the text defined in the LPR Stub text box, along with the LPR Stub Confidence value:

** *LPR Stub* - For example, "NOREAD"

** *LPR Stub Confidence* - For example, 0

* *Hybrid Pre Time (for Hybrid mode only)* - Time in milliseconds before the trigger to search for the closest Event to the trigger (see <<f_Illustration-of-Hybrid-Pre-Post-Time>>)

* *Hybrid Post Time (for Hybrid mode only)* - Time in milliseconds after the trigger to search for the closest Event to the trigger (see <<f_Illustration-of-Hybrid-Pre-Post-Time>>)
+
[#f_Illustration-of-Hybrid-Pre-Post-Time]

.Illustration of Hybrid Pre/Post Time

image::./UserGuide/image27.png[image,width=624,height=170]

** Trigger 1 will be checked against the Hybrid Pre/Post time and use the closest Event - Event 1 or Event 2 (most likely). Note that Trigger 1 is closest to +++<u>+++Event+++</u>+++ 2, even though it is closer to the +++<u>+++best LPR frame+++</u>+++ in Event 1.

** Trigger 2 will use Event 2.

** Trigger 3 will wait for a new Event. If a new Event does not arrive within the Hybrid Post Time, a trigger Event will be created, without an LPR read, but with associated images and a timestamp.

+++<div class="pagebreak"> </div>+++

[#s_Lanes]

=== Lanes

[#f_Lanes-Section]

.Lanes Section

image::./UserGuide/image28.png[image,width=617,height=87]

* Actions:

** +++<u>+++Edit+++</u>+++ - Edit the Lane's parameters

** +++<u>+++Delete+++</u>+++ - Delete the Lane (a warning will be displayed)

** +++<u>+++Trigger+++</u>+++ - Send a software trigger immediately to {shortprodname} (works in all modes except NonTriggered)
+
[NOTE]

========================================

Each Lane number must be unique in the overall IZ ALPR system.

The images from all cameras capturing the same physical lane will be combined into a single Event.

Each "Lane" is actually a virtual Lane. For example, if you have two Camera Systems capturing the same physical lane, you will need to create two different "Lanes", and associate each Camera System's cameras with a different "Lane".

========================================
+
[#f_Add-Edit-Lane-Dialog]

.Add/Edit Lane Dialog

image::./UserGuide/image29.png[image,width=265,height=151]

* *ID* (required) - The identification number of the lane to be captured by the cameras. This number will appear associated with Events in the Live tab (see <<s_Live-Journal-Tab>>).

* *Name* (required) - The name of the Lane as it will appear in the GUI. This name will also be sent in HTTP and {software-protocol} messages.
+
[NOTE]

========================================

If you have upgraded from a previous {shortprodname} version
in which only Lane IDs were specified, Lane names will
be automatically assigned the word "Lane" plus the Lane ID.

========================================

* *Avg Speed (for DOT cameras only)* - The average vehicle speed expected in this Lane

* *Distance* *(for DOT cameras only)* - The distance between the trigger device and the camera

* *Location (for ALPR cameras only)* - Select one of the following options:

** +++<u>+++Unknown+++</u>+++ - The camera's position relative to vehicles is unknown.

** +++<u>+++Front+++</u>+++ - The camera in this Lane is capturing images from the front of vehicles

** +++<u>+++Rear+++</u>+++ - The camera in this Lane is capturing images from the rear of vehicles

* *Passageway (for specific sites)* - Select one of the following options
(see <<s_Passageway-Combination>>):

** +++<u>+++Unknown+++</u>+++ - It is unknown if the camera in this Lane
is capturing entering or exiting vehicles

** +++<u>+++Entry+++</u>+++ - The camera in this Lane is capturing images from
vehicles entering

** +++<u>+++Exit+++</u>+++ - The camera in this Lane is capturing images from
vehicles exiting

* *Ignore Opposite Direction* - if enabled, then all Events for vehicles
moving in the direction opposite to the direction arrow in the Calibration
tab will be ignored (see <<s_Calibration-Tab>>). Note that you can add
a Direction column to the Live and Search tabs using the multi-line menu at the upper
right of the screen (see <<s_Live-Journal-Tab>>).

+++<div class="pagebreak"> </div>+++

[#s_Cameras]

=== Cameras

[#f_Cameras-Section]

.Cameras Section

image::./UserGuide/RV-1_15-FIG-215_Cameras.png[image,width=695,height=112]

[NOTE]

========================================

If you are using an IZMobileLPI system, contact {compname-short} for details on how to set the camera parameters.

========================================

* Actions:

** +++<u>+++Edit+++</u>+++ - Edit the camera's parameters (see <<f_Add-Edit-Camera-Dialog>>)

** +++<u>+++Delete+++</u>+++ - Delete the camera (a warning will be displayed)

* *Camera table headers:* Camera ID, Lane ID, Name, URL, Type (as configured when the camera was added)

* *Image* - Thumbnail image from a recent camera image
+
[WARNING]

========================================

If you add a camera, or edit a camera's parameters and click the Save button in this dialog (even if you did not change the URL), you may see a warning icon in the Image column. The reappearance of the image indicates that the core software has restarted, and Events will resume being captured and displayed in the Live tab, with the following changes: +
- The Transaction ID will restart at 1 for that camera. +
- The history of previous Events for that camera will be cleared

========================================

*Add Camera* (button at end of Cameras section):

[#f_Add-Edit-Camera-Dialog]

.Add/Edit Camera Dialog

image::./UserGuide/RV-1_15-FIG-216_EditCamera.png[image,width=230,height=272]

<<<

* *Lane ID* - The identification number of the lane being captured by the camera(s). Select a Lane number you defined (see <<s_Lanes>>). This number will appear associated with Events in the Live tab (see <<s_Live-Journal-Tab>>).
+
[NOTE]

========================================

The images from all cameras capturing the same physical lane will be combined into a single Event.

Using the same Lane ID for different cameras (even the LPR and OV cameras within the same Camera System) will combine the reads into one Event (see <<s_Lanes>>). You may even be able to improve read accuracy by changing the zoom to have one camera "see" closer than the other one.

You could also position cameras to be in different positions (front/rear as in a toll plaza).

========================================

* *Camera ID* - For internal use; should be unique in the overall IZ ALPR system

* *Name* - Camera name for internal use; should be unique in the overall IZ ALPR system

* *URL* - RTSP or HTTP URL:

** RTSP stream URL example: +
rtsp://<camera IP address>/cam0_0

** HTTP URL example: +
\http://<camera IP address>

* *Type* - Type of camera (LPR, View or DriverFace) +
+
[IMPORTANT]
============================

The Trigger Pre and Trigger Post parameters cannot both be zero.

============================


* *Trigger Pre* (used in Triggered mode types only) - Number of frames
to be included in the set of frames used to build an Event -
+++<u>+++before+++</u>+++ the trigger occurs
(see <<f_Trigger-Sources-and-Sequence>>).

* *Trigger Post* (used in Triggered mode types only) -
Number of frames to be included in the set of frames used to build an
Event - +++<u>+++after+++</u>+++ the trigger occurs
(see <<f_Trigger-Sources-and-Sequence>>)

+++<div class="pagebreak"> </div>+++

[#s_Live-Journal-Tab]

== Live (Journal) Tab

[#f_Live-Journal-Tab-with-Row-Selected]

.Live (Journal) Tab with Row Selected

image::./UserGuide/RV-1_15-FIG-210_NewLiveTab.png[image,width=554,height=243]

The Live tab displays Events and other data about each Event.

[NOTE]

========================================

The Events displayed in the Live tab are being simultaneously sent via the protocols you selected in the Settings tab.

You should see that Events are being generated for each vehicle passing each camera, with sufficient recognition accuracy and confidence. If not, see <<s_Troubleshooting>> for troubleshooting tips.

If you return to the Live tab from another tab, the large picture returns to the LPR (black and white) camera image.

DOT (USDOT number image capture) cameras generate Events, but without LPR reads.

========================================

* Each row includes (additional items can be added from the multi-line menu icon > Configure Journal selection - see <<s_Live-Journal-Tab>>):

** +++<u>+++Transaction (Event) ID+++</u>+++. Note that each camera has its own Transaction ID sequence, so the same IDs may be used for different cameras.

** +++<u>+++Lane Name+++</u>+++ - Lane name as configured for the camera(s) viewing this lane in the Settings tab - see <<s_Lanes>>

** +++<u>+++Date and time+++</u>+++ when the Event was recorded

** +++<u>+++License Plate number (LPR)+++</u>+++

** +++<u>+++Recognition confidence+++</u>+++, expressed as a percentage

** To add columns to the Live (and Search) tab displays:

*** Click on the multi-line menu icon at the upper right of the {shortprodname} screen

*** Select "Configure Journal"
+
[#f_Configure-Journal-Multi-line-Menu]

.Configure Journal (Multi-line Menu)

image::./UserGuide/RV-1_15-FIG-021a_ConfigureJournal.png[image,width=80]

*** Select the additional columns to display, such as: +++<u>+++State+++</u>+++ (state displayed on plate), +++<u>+++State Confidence+++</u>+++ (confidence that the state has been recognized accurately), +++<u>+++Class+++</u>+++ (vehicle class, such as car or truck), +++<u>+++Class Confidence+++</u>+++ (confidence that the class has been recognized accurately) and +++<u>+++Direction+++</u>+++ (direction vehicle was traveling - forward or backward - according to the direction arrow configured in the Calibration tab - see <<s_Calibration-Tab>>). (These additional columns will also appear on the Search tab - see <<s_Search-Tab>>.)

* Pause/Run mode:

** Pause the grid display by clicking on a row,
or by using the pause button in the middle of
the controls under the large image
(image:./UserGuide/RV-Pause-Button.png[image,width=10)]).
You can also click on the large image to toggle between Pause and Run mode. This is useful if you want to examine a specific Event.

** You can also use these controls to move
through the grid (next/previous Event, or
start/end of Events).

** Start the display running in real-time again
using the Run button
(image:./UserGuide/RV-Run-Button.png[image,width=20])
or by clicking on the large image. This will refresh the display, and resume displaying Events, starting from the 20 most recent Events.
+
[NOTE]

========================================

{shortprodname} is continually recording and saving (Journal) Events. The Events are added to the Live display (Running mode operation) until the display is paused. Even when you pause the Live display, {shortprodname} continues to record Events - and can display up to a maximum of 20 recent Events.

As you Pause/Run the Live grid,
you may see momentary icons
( image:./UserGuide/RV-Pause-Button.png[image,width=10)]
image:./UserGuide/RV-Run-Button.png[image,width=20]) appearing in the middle of the
large image pane to indicate the mode.

========================================

* The text below the Pause/Run controls displays a summary of the Event's information.

* The thumbnail images below the
larger image pane display the overview (first row), LPR (second row)
and plate patch (third row) images from each camera.

** (For triggered modes) Images with a blue
border are pre-trigger frames (see <<f_Add-Edit-Camera-Dialog>>)
** (For triggered modes) Images with an orange
border are post-trigger frames (see <<f_Add-Edit-Camera-Dialog>>)
** Hover over a thumbnail to display date/time
information for each camera or confidence
for the plate patch images.
** Click on a thumbnail to display
it in the larger image pane.

<<<

* Zoom in on an area of interest in the large image (requires a mouse with a wheel):

** Pause the grid

** Hover (do not click) over the area of interest; the cursor will change to a magnifying glass.

** Mouse wheel up a little at a time to enlarge the image

** As the image enlarges, you may need to readjust the cursor position to re-focus on the area of interest

* To save images, right-click on the large image pane, and save the image

+++<div class="pagebreak"> </div>+++

[#s_Search-Tab]

== Search Tab

[#f_Search-Tab]

.Search Tab

image::./UserGuide/RV-1_15-FIG-211_NewSearchTab.png[image,width=645,height=307]

The Search tab enables you to search for Event records stored in the {shortprodname} database.

[NOTE]

========================================

The same columns that were added to the Live display (using the multi-line menu at the upper right of the screen) will also appear in the Search display (see <<s_Live-Journal-Tab>>).

========================================

[#s_Search-Tab-Page-Controls]

=== Search Tab: Page Controls

Page controls are located at the upper right
of the records grid:

[#f_Search-Tab-Page-Controls]

.Search Tab: Page Controls

image::./UserGuide/image35.png[image,width=424,height=193]

+++<div class="pagebreak"> </div>+++

[#s_Search-Tab-Filters]

=== Search Tab: Filters

Filter boxes are located at the top of each column; you can click on the question mark icons to show explanations of what you can enter in each filter box.

[IMPORTANT]

========================================

After applying filters, remember that you will need to use the page controls to see all of the filtered records. For example, if there are 85 results, but you configured the grid to display 20 records per page, you must use the page controls to see the filtered records appearing on each page.

========================================

* *Numeric filters* (Event ID, Confidences) - Enter a specific number (example '30'), a number and a '>' symbol (example '>30') or a number and a '<' symbol (example '<30')

* *Lane Name* - Select All, or a specific lane

* *Time* - Click in the filter box to display a date/time selection popup. Uncheck the check box to clear the filter (see <<f_Search-Tab-Time-Filter-Selection-Popup>>).
+
[#f_Search-Tab-Time-Filter-Selection-Popup]

.Search Tab: Time Filter Selection Popup

image::./UserGuide/image36.png[image,width=317,height=308]

** Use the buttons at the top of the From/To sections to move between months

** Use the calendar grids to select dates

** Use the sliders to specify time

** Click the Now button to select the current time/date

* *Text filters* (LPR, State, Class) - Enter characters to find within the strings. For example, KZ will find **+++<u>+++KZ+++</u>+++**R3791 and J**+++<u>+++KZ+++</u>+++**0714.

* *Direction* - Select All, Forward, (Unknown) or Backward

+++<div class="pagebreak"> </div>+++

[#s_System-Status-Tab]

== System Status Tab

[#f_System-Status-Tab]

//remember to update this image file with the
//latest version when the software is released
//to production

image::./UserGuide/RV-1_15-FIG-205_SystemStatus.png[image,width=400]

This tab displays statuses of different {shortprodname}
components.

[NOTE]

============================

In order to see the illuminator status information,
you must enable its display on the System Info tab (see <<s_System-Info-Tab>>).

============================

[#s_Calibration-Tab]

== Calibration Tab

[#f_Calibration-Tab]

.Calibration Tab

image::./UserGuide/image37.png[image,width=624,height=313]

. When you see a vehicle at a typical capture position on the video, click on the video to pause it.

. It is recommended to use the view called "Draw image by maintaining aspect ratio (two-headed arrow)". You select this view by clicking on the right-most button at the upper left of the screen: image:./UserGuide/image38.png[image,width=18,height=11]

. Select a camera from the dropdown list (LPR or OV).

. The Frame Width (horizontal) and Frame Height (vertical) are displayed at the lower left, and are set automatically according to the Camera's hardware configuration. See your Camera's Installation and Calibration Guide.

. The Frame Timestamp at the lower left displays the date and time that the image is being taken/was taken by the camera.

. Aim the camera using the mounting bracket's adjustment hardware (see <<f_Pan-Tilt-Roll-Angle-Adjustments>>).

.. *Pan*: Adjust the Pan so that the image of the license plate is in the horizontal middle of the Field of View.

.. *Tilt:* Adjust the Tilt so that the image of every expected plate position (depending on the vehicle type, such as passenger cars, jeeps, trucks, etc.) will be in the middle of the screen (from top to bottom).

.. *Roll*: Adjust the Roll so the license plate's image is horizontally straight, parallel to the ground (not tilted to one side).
+
[#f_Pan-Tilt-Roll-Angle-Adjustments]

.Pan/Tilt/Roll (Angle) Adjustments

image::ROOT:RoadViewALPR/PanTiltRoll.png[image,width=311,height=186]

. When the correct position is achieved, make a preliminary tightening of the mounting screws.

. Define the Region of Interest (*ROI*) by dragging on the corners (vertices) of the trapezoidal region. For optimum recognition accuracy, the ROI should be large enough to capture the region where plates could be found in images.
+
[NOTE]

========================================

The following settings for the LPR and OV cameras are saved separately. For example, you may want a Region of Interest that is different for each camera.

========================================

. Define the *Plate Width Min*: Events will only be created for plate reads whose width is greater than or equal to this parameter. It is recommended to enter 150 in the *Plate Width Min* text box. +
This parameter can also be configured by dragging the small circle on the horizontal line on the Calibration tab (expressed in pixels). +
This parameter can be used to ignore small plate reads. For example, if the image was taken when a vehicle is too far away, the characters are too small to be read - even by a human.

. Define the *Plate Width Max*: Events will only be created for plate reads whose width is less than or equal to this parameter. It is recommended to enter approximately 350 in the *Plate Width Max* text box. +
This parameter can also be configured by dragging the large circle on the horizontal line on the Calibration tab (expressed in pixels). +
This parameter can be used to prevent false reads, such as large numbers on trucks.

. Use the zoom and focus buttons to adjust the view of the video until the width of the plate is 150 pixels, and its plate image is clear and sharp. (The surrounding items, such as the vehicle body, do not need to be as sharp as the plate.)
+
[IMPORTANT]

========================================

There is a delay between a click of a zoom/focus button and when you see the effect on the screen. Be sure to wait until you see the change on the screen before clicking the button again. Clicking the button multiple times will cause you to "overshoot" the desired zoom/focus.

As you adjust the zoom and focus, you may need to reposition the camera in order to get the image of the plate back to the desired position.

========================================

. *Direction (red arrow on video):*
//I have a note for future use that says as follows;
//has this been implemented yet?:
//TEXT FOR FUTURE: This Direction is used in
//NonTriggered mode to provide more accurate
//video-based triggering.}
Drag the head of the arrow around to point
to the angle at which you expect vehicles to be moving**.**
(The vehicle's direction is also sent to the {software-cloud} as part
of an Event.) You can add a Direction column to the Live and Search tabs
using the multi-line menu at the upper right of the screen (see <<s_Live-Journal-Tab>>). +
You can set the "Ignore Opposite Direction" parameter in the Lanes section
to ignore all Events for vehicles moving in the direction opposite to the
direction arrow (see <<s_Lanes>>).

. When you have finished, click the *Save* button. Wait several seconds for the display to refresh automatically, which indicates that the {shortprodname} recognition software is running again with the updated parameters.

. When the correct position is achieved, make a final tightening of the mounting hardware.

. Repeat these steps for the other camera.

+++<div class="pagebreak"> </div>+++

[#s_System-Info-Tab]

== System Info Tab

[#f_System-Info-Tab]

.System Info Tab

//remember to update this image file with the
//latest version when the software is released
//to production

image::./UserGuide/RV-1_15-FIG-034d_SystemInfo.png[image,width=400]

[NOTE]

========================================

Some System Info sections may not appear depending on your version of {shortprodname}

========================================

[#s_System-Info-Tab-System-Info-Section]

=== System Info Tab: System Info Section

This section provides the same information as in the upper right corner of the same Settings tab, namely the model, part number and serial number of the camera(s) {shortprodname} is communicating with.

[#s_System-Info-Tab-Firmware-Section]

=== System Info Tab: Firmware Section

* *Firmware Version* - The firmware version of the IZIC board (proprietary {compname-short} electronics) in the Camera System/DPU

* *New Firmware* - Enables you to update new firmware in the IZIC board

** Choose File - click this button to browse for the firmware file

** Update Firmware - click this button to update the firmware using the file you chose

[#s_System-Info-Tab-Illuminator-Status-Section]

=== System Info Tab: Illuminator Status Section

When enabled, illuminator status items are displayed
on the System Status tab (see <<s_System-Status-Tab>>), and these status
items are sent via {software-protocol}.

[#s_System-Info-Tab-Night-Mode-Section-for-Specific-Camera-Models-Only]

=== System Info Tab: Night Mode Section (for Specific Camera Models Only)

These parameters affect how {shortprodname} controls an external illuminator:

* Night Mode

** +++<u>+++Disable+++</u>+++ - never trigger the illuminator

** +++<u>+++Enable+++</u>+++ - camera and external illuminator behavior are optimized for night-time recognition. Recommended use is for calibration.

*** *OV LED Intensity* - Relative intensity of the built-in white LEDs, expressed as a percentage of the maximum possible intensity

*** *Illuminator Intensity* - (for IZS illuminators, synchronized with the Overview camera) Relative intensity of an external illuminator's LEDs, expressed as a percentage of the maximum possible intensity

** +++<u>+++Auto+++</u>+++ - automatically senses day/night, in order to decide whether to trigger an external illuminator, according to the Camera System's location (as defined by the Latitude and Longitude parameters). For the Auto mode, additional parameters appear:
+
[NOTE]

========================================

Latitude and Longitude are user-entered coordinates; determine them using Google maps, by clicking on the location where the Camera System will be installed (remember to put in a minus sign as needed)

========================================

*** *Latitude* - latitude coordinate of Camera System's location

*** *Longitude* - longitude coordinate of Camera System's location

*** *Post-Sunrise Offset* - time after actual sunrise to be considered as the start of the day

*** *Pre-Sunset Offset* - time before actual sunset to be considered the end of the day

* *Remember to click the Save button at the end of this section after making changes.*

[#s_System-Info-Tab-LPR-LED]

=== System Info Tab: LPR LED

These parameters enable you to control the camera's built-in IR LEDs.

* *Mode*

** +++<u>+++Off+++</u>+++ - LEDs off

** +++<u>+++Multi-flash+++</u>+++ - Each frame is illuminated with a different light intensity

** +++<u>+++Anti-flickering+++</u>+++ - Reduces the visible flickering of the built-in IR LED illumination by disabling multi-flash mode and adjusting flash frequency

* *Intensity* - light intensity in percent, where 0 is no light, and 100 is maximum light

+++<div class="pagebreak"> </div>+++

[#s_Troubleshooting]

== Troubleshooting

[NOTE]

========================================

For details about items in the following list related to hardware or configuration, see your camera's Installation and Calibration Guide.

========================================

[#t_Troubleshooting]

.Troubleshooting

[table.withborders,width="100%",cols="35%,65%",options="header",]
|===
|Symptom |Possible Solution
|Thumbnails in Settings tab (in the Camera section at the
bottom) have been replaced by red exclamation points and/or +
The Live tab and Search tab are empty (no Events are detected) a|
* Verify that each camera's IP address in the Camera System (or connected to the DPU), and the {shortprodname} computer's IP address are all on the same subnet.

* Verify that stable power at the correct level is being supplied to the cameras, even when under a heavy processing load.

* Verify that the IP address(es) configured in {shortprodname} match the IP addresses that you configured in the camera(s). See <<s_Cameras>>.

|Recognition rates are low a|
* On the Calibration tab, increase the size of the Region of Interest (ROI) - it may be too small to capture plates with high confidence

* On the Calibration tab, try to reduce the Plate Width Min and increase the Plate Width Max

Examine the video from the camera on the Calibration tab:

* If all license plates are not fully visible, re-aim the
camera so that the camera's field of view fully covers the capture zone. For a more precise adjustment, verify that the license plate's images are as close to the middle of the video display as possible.

* If the images are spotted, remove dirt and dust from
the front window of the camera with a soft cloth and mild soap

* If the images are not sharp, adjust the zoom and focus of the camera

|===

+++<div class="pagebreak"> </div>+++

== Notice and Legal Disclaimer

include::ROOT:partial$p-front-matter-notice.adoc[Front Matter Notice]

include::ROOT:partial$p-legal-disclaimer.adoc[Legal Disclaimer]

include::ROOT:partial$p-footer-copyright-short.adoc[Short Copyright Notice]

Doc. No. RV-ALPR-MAN-001
